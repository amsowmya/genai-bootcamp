{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "5327b587",
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing_extensions import Literal\n",
    "from langchain_core.tools import tool\n",
    "from langchain_groq import ChatGroq\n",
    "from langgraph.graph import StateGraph, MessagesState, START, END\n",
    "from langgraph.types import Command\n",
    "from dotenv import load_dotenv\n",
    "from IPython.display import display, Image\n",
    "from langchain_core.messages import BaseMessage, HumanMessage\n",
    "from langgraph.prebuilt import create_react_agent\n",
    "from typing import Annotated\n",
    "from langchain_experimental.utilities import PythonREPL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "475b90a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "load_dotenv()\n",
    "import os\n",
    "\n",
    "groq_api_key = os.getenv(\"GROQ_API_KEY\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "03acfb2d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"It's nice to meet you. Is there something I can help you with or would you like to chat?\""
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "llm = ChatGroq(groq_api_key=groq_api_key, model_name=\"llama-3.3-70b-versatile\")\n",
    "\n",
    "llm.invoke(\"hi\").content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "4c9e7e09",
   "metadata": {},
   "outputs": [],
   "source": [
    "def add_numbers(state):\n",
    "    result = state[\"num1\"]+state[\"num2\"]\n",
    "    print(f\"additional result: {result}\")\n",
    "    return Command(goto=\"multiply\", update={\"sum\": result})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "81a16203",
   "metadata": {},
   "outputs": [],
   "source": [
    "state={\"num1\":1, \"num2\": 2}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "bb4bda80",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "additional result: 3\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Command(update={'sum': 3}, goto='multiply')"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "add_numbers(state)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "4ab10fab",
   "metadata": {},
   "outputs": [],
   "source": [
    "@tool \n",
    "def transfer_to_multiplication_expert():\n",
    "    \"\"\"Ask multiplication agent for help\"\"\"\n",
    "    return\n",
    "\n",
    "\n",
    "@tool \n",
    "def transfer_to_addition_expert():\n",
    "    \"\"\"Ask addition agent for help\"\"\"\n",
    "    return"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "8a8dd818",
   "metadata": {},
   "outputs": [],
   "source": [
    "llm_with_tool = llm.bind_tools([transfer_to_multiplication_expert])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "f45ff6b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "ai_message = llm_with_tool.invoke(\"hi how are you\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "dac9c923",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[]"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ai_message.tool_calls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "fd4aec06",
   "metadata": {},
   "outputs": [],
   "source": [
    "ai_message = llm_with_tool.invoke(\"what's (3 + 5) *12. Provide me the output\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "ac3c97b3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AIMessage(content='', additional_kwargs={'tool_calls': [{'id': 'call_wgr8', 'function': {'arguments': '{}', 'name': 'transfer_to_multiplication_expert'}, 'type': 'function'}]}, response_metadata={'token_usage': {'completion_tokens': 13, 'prompt_tokens': 224, 'total_tokens': 237, 'completion_time': 0.047272727, 'prompt_time': 0.022284425, 'queue_time': 0.057505654, 'total_time': 0.069557152}, 'model_name': 'llama-3.3-70b-versatile', 'system_fingerprint': 'fp_3f3b593e33', 'finish_reason': 'tool_calls', 'logprobs': None}, id='run-0533e6b1-37c7-4ca7-b8dc-432037c3fd2e-0', tool_calls=[{'name': 'transfer_to_multiplication_expert', 'args': {}, 'id': 'call_wgr8', 'type': 'tool_call'}], usage_metadata={'input_tokens': 224, 'output_tokens': 13, 'total_tokens': 237})"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ai_message"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "41a342c4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'name': 'transfer_to_multiplication_expert',\n",
       "  'args': {},\n",
       "  'id': 'call_wgr8',\n",
       "  'type': 'tool_call'}]"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ai_message.tool_calls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "971d534d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def multiplication_expert(state: MessagesState) -> Command[Literal[\"additional_expert\", \"__end__\"]]:\n",
    "    \n",
    "    system_prompt = (\n",
    "        \"You are a multiplication expert, you can ask an addition expert for help with addition. \"\n",
    "        \"Always do your portion of calculation before the handoff.\"\n",
    "    )\n",
    "    \n",
    "    messages = [{\"role\": \"system\", \"content\": system_prompt}] + state['messages']\n",
    "    \n",
    "    ai_msg= llm.bind_tools([transfer_to_addition_expert]).invoke(messages)\n",
    "    \n",
    "    if len(ai_msg.tool_calls) > 0:\n",
    "        tool_call_id = ai_msg.tool_calls[-1][\"id\"]\n",
    "        tool_msg = {\n",
    "            \"role\": \"tool\",\n",
    "            \"content\": \"Successfully transferred\",\n",
    "            \"tool_call_id\": tool_call_id\n",
    "        }\n",
    "        return Command(goto=\"additional_expert\", update={\"messages\": [ai_msg, tool_msg]})\n",
    "    return {\"messages\": [ai_msg]}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "e8f4c6b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def additional_expert(state: MessagesState) -> Command[Literal[\"additional_expert\", \"__end__\"]]:\n",
    "    \n",
    "    system_prompt = (\n",
    "        \"You are a addition expert, you can ask an multiplication expert for help with multiplication. \"\n",
    "        \"Always do your portion of calculation before the handoff.\"\n",
    "    )\n",
    "    \n",
    "    messages = [{\"role\": \"system\", \"content\": system_prompt}] + state['messages']\n",
    "    \n",
    "    ai_msg= llm.bind_tools([transfer_to_multiplication_expert]).invoke(messages)\n",
    "    \n",
    "    if len(ai_msg.tool_calls) > 0:\n",
    "        tool_call_id = ai_msg.tool_calls[-1][\"id\"]\n",
    "        tool_msg = {\n",
    "            \"role\": \"tool\",\n",
    "            \"content\": \"Successfully transferred\",\n",
    "            \"tool_call_id\": tool_call_id\n",
    "        }\n",
    "        return Command(goto=\"multiplication_expert\", update={\"messages\": [ai_msg, tool_msg]})\n",
    "    return {\"messages\": [ai_msg]}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "eb97e026",
   "metadata": {},
   "outputs": [],
   "source": [
    "graph = StateGraph(MessagesState)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "4f002eb4",
   "metadata": {},
   "outputs": [],
   "source": [
    "graph.add_node(\"additional_expert\", additional_expert)\n",
    "graph.add_node(\"multiplication_expert\", multiplication_expert)\n",
    "\n",
    "graph.add_edge(START, \"additional_expert\")\n",
    "\n",
    "app = graph.compile()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "30e79a0b",
   "metadata": {},
   "outputs": [
    {
     "ename": "ReadTimeout",
     "evalue": "HTTPSConnectionPool(host='mermaid.ink', port=443): Read timed out. (read timeout=10)",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mTimeoutError\u001b[39m                              Traceback (most recent call last)",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\sowmy\\anaconda3\\envs\\langgraph\\Lib\\site-packages\\urllib3\\connectionpool.py:534\u001b[39m, in \u001b[36mHTTPConnectionPool._make_request\u001b[39m\u001b[34m(self, conn, method, url, body, headers, retries, timeout, chunked, response_conn, preload_content, decode_content, enforce_content_length)\u001b[39m\n\u001b[32m    533\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m534\u001b[39m     response = \u001b[43mconn\u001b[49m\u001b[43m.\u001b[49m\u001b[43mgetresponse\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    535\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m (BaseSSLError, \u001b[38;5;167;01mOSError\u001b[39;00m) \u001b[38;5;28;01mas\u001b[39;00m e:\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\sowmy\\anaconda3\\envs\\langgraph\\Lib\\site-packages\\urllib3\\connection.py:516\u001b[39m, in \u001b[36mHTTPConnection.getresponse\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m    515\u001b[39m \u001b[38;5;66;03m# Get the response from http.client.HTTPConnection\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m516\u001b[39m httplib_response = \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m.\u001b[49m\u001b[43mgetresponse\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    518\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\sowmy\\anaconda3\\envs\\langgraph\\Lib\\http\\client.py:1411\u001b[39m, in \u001b[36mHTTPConnection.getresponse\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m   1410\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m1411\u001b[39m     \u001b[43mresponse\u001b[49m\u001b[43m.\u001b[49m\u001b[43mbegin\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1412\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mConnectionError\u001b[39;00m:\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\sowmy\\anaconda3\\envs\\langgraph\\Lib\\http\\client.py:324\u001b[39m, in \u001b[36mHTTPResponse.begin\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m    323\u001b[39m \u001b[38;5;28;01mwhile\u001b[39;00m \u001b[38;5;28;01mTrue\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m324\u001b[39m     version, status, reason = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_read_status\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    325\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m status != CONTINUE:\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\sowmy\\anaconda3\\envs\\langgraph\\Lib\\http\\client.py:285\u001b[39m, in \u001b[36mHTTPResponse._read_status\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m    284\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34m_read_status\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n\u001b[32m--> \u001b[39m\u001b[32m285\u001b[39m     line = \u001b[38;5;28mstr\u001b[39m(\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mfp\u001b[49m\u001b[43m.\u001b[49m\u001b[43mreadline\u001b[49m\u001b[43m(\u001b[49m\u001b[43m_MAXLINE\u001b[49m\u001b[43m \u001b[49m\u001b[43m+\u001b[49m\u001b[43m \u001b[49m\u001b[32;43m1\u001b[39;49m\u001b[43m)\u001b[49m, \u001b[33m\"\u001b[39m\u001b[33miso-8859-1\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m    286\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(line) > _MAXLINE:\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\sowmy\\anaconda3\\envs\\langgraph\\Lib\\socket.py:707\u001b[39m, in \u001b[36mSocketIO.readinto\u001b[39m\u001b[34m(self, b)\u001b[39m\n\u001b[32m    706\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m707\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_sock\u001b[49m\u001b[43m.\u001b[49m\u001b[43mrecv_into\u001b[49m\u001b[43m(\u001b[49m\u001b[43mb\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    708\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m timeout:\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\sowmy\\anaconda3\\envs\\langgraph\\Lib\\ssl.py:1249\u001b[39m, in \u001b[36mSSLSocket.recv_into\u001b[39m\u001b[34m(self, buffer, nbytes, flags)\u001b[39m\n\u001b[32m   1246\u001b[39m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[32m   1247\u001b[39m           \u001b[33m\"\u001b[39m\u001b[33mnon-zero flags not allowed in calls to recv_into() on \u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[33m\"\u001b[39m %\n\u001b[32m   1248\u001b[39m           \u001b[38;5;28mself\u001b[39m.\u001b[34m__class__\u001b[39m)\n\u001b[32m-> \u001b[39m\u001b[32m1249\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mread\u001b[49m\u001b[43m(\u001b[49m\u001b[43mnbytes\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbuffer\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1250\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\sowmy\\anaconda3\\envs\\langgraph\\Lib\\ssl.py:1105\u001b[39m, in \u001b[36mSSLSocket.read\u001b[39m\u001b[34m(self, len, buffer)\u001b[39m\n\u001b[32m   1104\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m buffer \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m1105\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_sslobj\u001b[49m\u001b[43m.\u001b[49m\u001b[43mread\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mlen\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbuffer\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1106\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n",
      "\u001b[31mTimeoutError\u001b[39m: The read operation timed out",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[31mReadTimeoutError\u001b[39m                          Traceback (most recent call last)",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\sowmy\\anaconda3\\envs\\langgraph\\Lib\\site-packages\\requests\\adapters.py:667\u001b[39m, in \u001b[36mHTTPAdapter.send\u001b[39m\u001b[34m(self, request, stream, timeout, verify, cert, proxies)\u001b[39m\n\u001b[32m    666\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m667\u001b[39m     resp = \u001b[43mconn\u001b[49m\u001b[43m.\u001b[49m\u001b[43murlopen\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    668\u001b[39m \u001b[43m        \u001b[49m\u001b[43mmethod\u001b[49m\u001b[43m=\u001b[49m\u001b[43mrequest\u001b[49m\u001b[43m.\u001b[49m\u001b[43mmethod\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    669\u001b[39m \u001b[43m        \u001b[49m\u001b[43murl\u001b[49m\u001b[43m=\u001b[49m\u001b[43murl\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    670\u001b[39m \u001b[43m        \u001b[49m\u001b[43mbody\u001b[49m\u001b[43m=\u001b[49m\u001b[43mrequest\u001b[49m\u001b[43m.\u001b[49m\u001b[43mbody\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    671\u001b[39m \u001b[43m        \u001b[49m\u001b[43mheaders\u001b[49m\u001b[43m=\u001b[49m\u001b[43mrequest\u001b[49m\u001b[43m.\u001b[49m\u001b[43mheaders\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    672\u001b[39m \u001b[43m        \u001b[49m\u001b[43mredirect\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[32m    673\u001b[39m \u001b[43m        \u001b[49m\u001b[43massert_same_host\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[32m    674\u001b[39m \u001b[43m        \u001b[49m\u001b[43mpreload_content\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[32m    675\u001b[39m \u001b[43m        \u001b[49m\u001b[43mdecode_content\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[32m    676\u001b[39m \u001b[43m        \u001b[49m\u001b[43mretries\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mmax_retries\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    677\u001b[39m \u001b[43m        \u001b[49m\u001b[43mtimeout\u001b[49m\u001b[43m=\u001b[49m\u001b[43mtimeout\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    678\u001b[39m \u001b[43m        \u001b[49m\u001b[43mchunked\u001b[49m\u001b[43m=\u001b[49m\u001b[43mchunked\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    679\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    681\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m (ProtocolError, \u001b[38;5;167;01mOSError\u001b[39;00m) \u001b[38;5;28;01mas\u001b[39;00m err:\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\sowmy\\anaconda3\\envs\\langgraph\\Lib\\site-packages\\urllib3\\connectionpool.py:841\u001b[39m, in \u001b[36mHTTPConnectionPool.urlopen\u001b[39m\u001b[34m(self, method, url, body, headers, retries, redirect, assert_same_host, timeout, pool_timeout, release_conn, chunked, body_pos, preload_content, decode_content, **response_kw)\u001b[39m\n\u001b[32m    839\u001b[39m     new_e = ProtocolError(\u001b[33m\"\u001b[39m\u001b[33mConnection aborted.\u001b[39m\u001b[33m\"\u001b[39m, new_e)\n\u001b[32m--> \u001b[39m\u001b[32m841\u001b[39m retries = \u001b[43mretries\u001b[49m\u001b[43m.\u001b[49m\u001b[43mincrement\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    842\u001b[39m \u001b[43m    \u001b[49m\u001b[43mmethod\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43murl\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43merror\u001b[49m\u001b[43m=\u001b[49m\u001b[43mnew_e\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m_pool\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m_stacktrace\u001b[49m\u001b[43m=\u001b[49m\u001b[43msys\u001b[49m\u001b[43m.\u001b[49m\u001b[43mexc_info\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m[\u001b[49m\u001b[32;43m2\u001b[39;49m\u001b[43m]\u001b[49m\n\u001b[32m    843\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    844\u001b[39m retries.sleep()\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\sowmy\\anaconda3\\envs\\langgraph\\Lib\\site-packages\\urllib3\\util\\retry.py:474\u001b[39m, in \u001b[36mRetry.increment\u001b[39m\u001b[34m(self, method, url, response, error, _pool, _stacktrace)\u001b[39m\n\u001b[32m    473\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m read \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mFalse\u001b[39;00m \u001b[38;5;129;01mor\u001b[39;00m method \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mself\u001b[39m._is_method_retryable(method):\n\u001b[32m--> \u001b[39m\u001b[32m474\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[43mreraise\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mtype\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43merror\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43merror\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m_stacktrace\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    475\u001b[39m \u001b[38;5;28;01melif\u001b[39;00m read \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\sowmy\\anaconda3\\envs\\langgraph\\Lib\\site-packages\\urllib3\\util\\util.py:39\u001b[39m, in \u001b[36mreraise\u001b[39m\u001b[34m(tp, value, tb)\u001b[39m\n\u001b[32m     38\u001b[39m         \u001b[38;5;28;01mraise\u001b[39;00m value.with_traceback(tb)\n\u001b[32m---> \u001b[39m\u001b[32m39\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m value\n\u001b[32m     40\u001b[39m \u001b[38;5;28;01mfinally\u001b[39;00m:\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\sowmy\\anaconda3\\envs\\langgraph\\Lib\\site-packages\\urllib3\\connectionpool.py:787\u001b[39m, in \u001b[36mHTTPConnectionPool.urlopen\u001b[39m\u001b[34m(self, method, url, body, headers, retries, redirect, assert_same_host, timeout, pool_timeout, release_conn, chunked, body_pos, preload_content, decode_content, **response_kw)\u001b[39m\n\u001b[32m    786\u001b[39m \u001b[38;5;66;03m# Make the request on the HTTPConnection object\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m787\u001b[39m response = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_make_request\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    788\u001b[39m \u001b[43m    \u001b[49m\u001b[43mconn\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    789\u001b[39m \u001b[43m    \u001b[49m\u001b[43mmethod\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    790\u001b[39m \u001b[43m    \u001b[49m\u001b[43murl\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    791\u001b[39m \u001b[43m    \u001b[49m\u001b[43mtimeout\u001b[49m\u001b[43m=\u001b[49m\u001b[43mtimeout_obj\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    792\u001b[39m \u001b[43m    \u001b[49m\u001b[43mbody\u001b[49m\u001b[43m=\u001b[49m\u001b[43mbody\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    793\u001b[39m \u001b[43m    \u001b[49m\u001b[43mheaders\u001b[49m\u001b[43m=\u001b[49m\u001b[43mheaders\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    794\u001b[39m \u001b[43m    \u001b[49m\u001b[43mchunked\u001b[49m\u001b[43m=\u001b[49m\u001b[43mchunked\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    795\u001b[39m \u001b[43m    \u001b[49m\u001b[43mretries\u001b[49m\u001b[43m=\u001b[49m\u001b[43mretries\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    796\u001b[39m \u001b[43m    \u001b[49m\u001b[43mresponse_conn\u001b[49m\u001b[43m=\u001b[49m\u001b[43mresponse_conn\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    797\u001b[39m \u001b[43m    \u001b[49m\u001b[43mpreload_content\u001b[49m\u001b[43m=\u001b[49m\u001b[43mpreload_content\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    798\u001b[39m \u001b[43m    \u001b[49m\u001b[43mdecode_content\u001b[49m\u001b[43m=\u001b[49m\u001b[43mdecode_content\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    799\u001b[39m \u001b[43m    \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mresponse_kw\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    800\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    802\u001b[39m \u001b[38;5;66;03m# Everything went great!\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\sowmy\\anaconda3\\envs\\langgraph\\Lib\\site-packages\\urllib3\\connectionpool.py:536\u001b[39m, in \u001b[36mHTTPConnectionPool._make_request\u001b[39m\u001b[34m(self, conn, method, url, body, headers, retries, timeout, chunked, response_conn, preload_content, decode_content, enforce_content_length)\u001b[39m\n\u001b[32m    535\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m (BaseSSLError, \u001b[38;5;167;01mOSError\u001b[39;00m) \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[32m--> \u001b[39m\u001b[32m536\u001b[39m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_raise_timeout\u001b[49m\u001b[43m(\u001b[49m\u001b[43merr\u001b[49m\u001b[43m=\u001b[49m\u001b[43me\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43murl\u001b[49m\u001b[43m=\u001b[49m\u001b[43murl\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtimeout_value\u001b[49m\u001b[43m=\u001b[49m\u001b[43mread_timeout\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    537\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\sowmy\\anaconda3\\envs\\langgraph\\Lib\\site-packages\\urllib3\\connectionpool.py:367\u001b[39m, in \u001b[36mHTTPConnectionPool._raise_timeout\u001b[39m\u001b[34m(self, err, url, timeout_value)\u001b[39m\n\u001b[32m    366\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(err, SocketTimeout):\n\u001b[32m--> \u001b[39m\u001b[32m367\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m ReadTimeoutError(\n\u001b[32m    368\u001b[39m         \u001b[38;5;28mself\u001b[39m, url, \u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mRead timed out. (read timeout=\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mtimeout_value\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m)\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m    369\u001b[39m     ) \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01merr\u001b[39;00m\n\u001b[32m    371\u001b[39m \u001b[38;5;66;03m# See the above comment about EAGAIN in Python 3.\u001b[39;00m\n",
      "\u001b[31mReadTimeoutError\u001b[39m: HTTPSConnectionPool(host='mermaid.ink', port=443): Read timed out. (read timeout=10)",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[31mReadTimeout\u001b[39m                               Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[35]\u001b[39m\u001b[32m, line 1\u001b[39m\n\u001b[32m----> \u001b[39m\u001b[32m1\u001b[39m display(Image(\u001b[43mapp\u001b[49m\u001b[43m.\u001b[49m\u001b[43mget_graph\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m.\u001b[49m\u001b[43mdraw_mermaid_png\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m))\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\sowmy\\anaconda3\\envs\\langgraph\\Lib\\site-packages\\langchain_core\\runnables\\graph.py:631\u001b[39m, in \u001b[36mGraph.draw_mermaid_png\u001b[39m\u001b[34m(self, curve_style, node_colors, wrap_label_n_words, output_file_path, draw_method, background_color, padding)\u001b[39m\n\u001b[32m    624\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mlangchain_core\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mrunnables\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mgraph_mermaid\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m draw_mermaid_png\n\u001b[32m    626\u001b[39m mermaid_syntax = \u001b[38;5;28mself\u001b[39m.draw_mermaid(\n\u001b[32m    627\u001b[39m     curve_style=curve_style,\n\u001b[32m    628\u001b[39m     node_colors=node_colors,\n\u001b[32m    629\u001b[39m     wrap_label_n_words=wrap_label_n_words,\n\u001b[32m    630\u001b[39m )\n\u001b[32m--> \u001b[39m\u001b[32m631\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mdraw_mermaid_png\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    632\u001b[39m \u001b[43m    \u001b[49m\u001b[43mmermaid_syntax\u001b[49m\u001b[43m=\u001b[49m\u001b[43mmermaid_syntax\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    633\u001b[39m \u001b[43m    \u001b[49m\u001b[43moutput_file_path\u001b[49m\u001b[43m=\u001b[49m\u001b[43moutput_file_path\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    634\u001b[39m \u001b[43m    \u001b[49m\u001b[43mdraw_method\u001b[49m\u001b[43m=\u001b[49m\u001b[43mdraw_method\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    635\u001b[39m \u001b[43m    \u001b[49m\u001b[43mbackground_color\u001b[49m\u001b[43m=\u001b[49m\u001b[43mbackground_color\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    636\u001b[39m \u001b[43m    \u001b[49m\u001b[43mpadding\u001b[49m\u001b[43m=\u001b[49m\u001b[43mpadding\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    637\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\sowmy\\anaconda3\\envs\\langgraph\\Lib\\site-packages\\langchain_core\\runnables\\graph_mermaid.py:215\u001b[39m, in \u001b[36mdraw_mermaid_png\u001b[39m\u001b[34m(mermaid_syntax, output_file_path, draw_method, background_color, padding)\u001b[39m\n\u001b[32m    209\u001b[39m     img_bytes = asyncio.run(\n\u001b[32m    210\u001b[39m         _render_mermaid_using_pyppeteer(\n\u001b[32m    211\u001b[39m             mermaid_syntax, output_file_path, background_color, padding\n\u001b[32m    212\u001b[39m         )\n\u001b[32m    213\u001b[39m     )\n\u001b[32m    214\u001b[39m \u001b[38;5;28;01melif\u001b[39;00m draw_method == MermaidDrawMethod.API:\n\u001b[32m--> \u001b[39m\u001b[32m215\u001b[39m     img_bytes = \u001b[43m_render_mermaid_using_api\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    216\u001b[39m \u001b[43m        \u001b[49m\u001b[43mmermaid_syntax\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43moutput_file_path\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbackground_color\u001b[49m\n\u001b[32m    217\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    218\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m    219\u001b[39m     supported_methods = \u001b[33m\"\u001b[39m\u001b[33m, \u001b[39m\u001b[33m\"\u001b[39m.join([m.value \u001b[38;5;28;01mfor\u001b[39;00m m \u001b[38;5;129;01min\u001b[39;00m MermaidDrawMethod])\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\sowmy\\anaconda3\\envs\\langgraph\\Lib\\site-packages\\langchain_core\\runnables\\graph_mermaid.py:333\u001b[39m, in \u001b[36m_render_mermaid_using_api\u001b[39m\u001b[34m(mermaid_syntax, output_file_path, background_color, file_type)\u001b[39m\n\u001b[32m    327\u001b[39m         background_color = \u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33m!\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mbackground_color\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m\"\u001b[39m\n\u001b[32m    329\u001b[39m image_url = (\n\u001b[32m    330\u001b[39m     \u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mhttps://mermaid.ink/img/\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mmermaid_syntax_encoded\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m\"\u001b[39m\n\u001b[32m    331\u001b[39m     \u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33m?type=\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mfile_type\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m&bgColor=\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mbackground_color\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m\"\u001b[39m\n\u001b[32m    332\u001b[39m )\n\u001b[32m--> \u001b[39m\u001b[32m333\u001b[39m response = \u001b[43mrequests\u001b[49m\u001b[43m.\u001b[49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[43mimage_url\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtimeout\u001b[49m\u001b[43m=\u001b[49m\u001b[32;43m10\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[32m    334\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m response.status_code == \u001b[32m200\u001b[39m:\n\u001b[32m    335\u001b[39m     img_bytes = response.content\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\sowmy\\anaconda3\\envs\\langgraph\\Lib\\site-packages\\requests\\api.py:73\u001b[39m, in \u001b[36mget\u001b[39m\u001b[34m(url, params, **kwargs)\u001b[39m\n\u001b[32m     62\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mget\u001b[39m(url, params=\u001b[38;5;28;01mNone\u001b[39;00m, **kwargs):\n\u001b[32m     63\u001b[39m \u001b[38;5;250m    \u001b[39m\u001b[33mr\u001b[39m\u001b[33;03m\"\"\"Sends a GET request.\u001b[39;00m\n\u001b[32m     64\u001b[39m \n\u001b[32m     65\u001b[39m \u001b[33;03m    :param url: URL for the new :class:`Request` object.\u001b[39;00m\n\u001b[32m   (...)\u001b[39m\u001b[32m     70\u001b[39m \u001b[33;03m    :rtype: requests.Response\u001b[39;00m\n\u001b[32m     71\u001b[39m \u001b[33;03m    \"\"\"\u001b[39;00m\n\u001b[32m---> \u001b[39m\u001b[32m73\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mrequest\u001b[49m\u001b[43m(\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mget\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43murl\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mparams\u001b[49m\u001b[43m=\u001b[49m\u001b[43mparams\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\sowmy\\anaconda3\\envs\\langgraph\\Lib\\site-packages\\requests\\api.py:59\u001b[39m, in \u001b[36mrequest\u001b[39m\u001b[34m(method, url, **kwargs)\u001b[39m\n\u001b[32m     55\u001b[39m \u001b[38;5;66;03m# By using the 'with' statement we are sure the session is closed, thus we\u001b[39;00m\n\u001b[32m     56\u001b[39m \u001b[38;5;66;03m# avoid leaving sockets open which can trigger a ResourceWarning in some\u001b[39;00m\n\u001b[32m     57\u001b[39m \u001b[38;5;66;03m# cases, and look like a memory leak in others.\u001b[39;00m\n\u001b[32m     58\u001b[39m \u001b[38;5;28;01mwith\u001b[39;00m sessions.Session() \u001b[38;5;28;01mas\u001b[39;00m session:\n\u001b[32m---> \u001b[39m\u001b[32m59\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43msession\u001b[49m\u001b[43m.\u001b[49m\u001b[43mrequest\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmethod\u001b[49m\u001b[43m=\u001b[49m\u001b[43mmethod\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43murl\u001b[49m\u001b[43m=\u001b[49m\u001b[43murl\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\sowmy\\anaconda3\\envs\\langgraph\\Lib\\site-packages\\requests\\sessions.py:589\u001b[39m, in \u001b[36mSession.request\u001b[39m\u001b[34m(self, method, url, params, data, headers, cookies, files, auth, timeout, allow_redirects, proxies, hooks, stream, verify, cert, json)\u001b[39m\n\u001b[32m    584\u001b[39m send_kwargs = {\n\u001b[32m    585\u001b[39m     \u001b[33m\"\u001b[39m\u001b[33mtimeout\u001b[39m\u001b[33m\"\u001b[39m: timeout,\n\u001b[32m    586\u001b[39m     \u001b[33m\"\u001b[39m\u001b[33mallow_redirects\u001b[39m\u001b[33m\"\u001b[39m: allow_redirects,\n\u001b[32m    587\u001b[39m }\n\u001b[32m    588\u001b[39m send_kwargs.update(settings)\n\u001b[32m--> \u001b[39m\u001b[32m589\u001b[39m resp = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43msend\u001b[49m\u001b[43m(\u001b[49m\u001b[43mprep\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43msend_kwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    591\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m resp\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\sowmy\\anaconda3\\envs\\langgraph\\Lib\\site-packages\\requests\\sessions.py:703\u001b[39m, in \u001b[36mSession.send\u001b[39m\u001b[34m(self, request, **kwargs)\u001b[39m\n\u001b[32m    700\u001b[39m start = preferred_clock()\n\u001b[32m    702\u001b[39m \u001b[38;5;66;03m# Send the request\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m703\u001b[39m r = \u001b[43madapter\u001b[49m\u001b[43m.\u001b[49m\u001b[43msend\u001b[49m\u001b[43m(\u001b[49m\u001b[43mrequest\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    705\u001b[39m \u001b[38;5;66;03m# Total elapsed time of the request (approximately)\u001b[39;00m\n\u001b[32m    706\u001b[39m elapsed = preferred_clock() - start\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\sowmy\\anaconda3\\envs\\langgraph\\Lib\\site-packages\\requests\\adapters.py:713\u001b[39m, in \u001b[36mHTTPAdapter.send\u001b[39m\u001b[34m(self, request, stream, timeout, verify, cert, proxies)\u001b[39m\n\u001b[32m    711\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m SSLError(e, request=request)\n\u001b[32m    712\u001b[39m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(e, ReadTimeoutError):\n\u001b[32m--> \u001b[39m\u001b[32m713\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m ReadTimeout(e, request=request)\n\u001b[32m    714\u001b[39m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(e, _InvalidHeader):\n\u001b[32m    715\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m InvalidHeader(e, request=request)\n",
      "\u001b[31mReadTimeout\u001b[39m: HTTPSConnectionPool(host='mermaid.ink', port=443): Read timed out. (read timeout=10)"
     ]
    }
   ],
   "source": [
    "display(Image(app.get_graph().draw_mermaid_png()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "fa1bc57c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'messages': [HumanMessage(content=\"what's (3 + 5) * 12. Provide me the output\", additional_kwargs={}, response_metadata={}, id='bc8b2896-897f-45e1-ad2a-b913e80488f3'),\n",
       "  AIMessage(content='', additional_kwargs={'tool_calls': [{'id': 'call_vn8j', 'function': {'arguments': '{\"num1\": 8, \"num2\": 12}', 'name': 'transfer_to_multiplication_expert'}, 'type': 'function'}]}, response_metadata={'token_usage': {'completion_tokens': 70, 'prompt_tokens': 253, 'total_tokens': 323, 'completion_time': 0.254545455, 'prompt_time': 0.01732379, 'queue_time': 0.05273995, 'total_time': 0.271869245}, 'model_name': 'llama-3.3-70b-versatile', 'system_fingerprint': 'fp_9a8b91ba77', 'finish_reason': 'tool_calls', 'logprobs': None}, id='run-feb75d37-5f05-4149-81d5-7554eec2d321-0', tool_calls=[{'name': 'transfer_to_multiplication_expert', 'args': {'num1': 8, 'num2': 12}, 'id': 'call_vn8j', 'type': 'tool_call'}], usage_metadata={'input_tokens': 253, 'output_tokens': 70, 'total_tokens': 323}),\n",
       "  ToolMessage(content='Successfully transferred', id='0b477131-d145-4d41-b00e-49d50ee23bcc', tool_call_id='call_vn8j'),\n",
       "  AIMessage(content='', additional_kwargs={'tool_calls': [{'id': 'call_jwfc', 'function': {'arguments': '{}', 'name': 'transfer_to_addition_expert'}, 'type': 'function'}]}, response_metadata={'token_usage': {'completion_tokens': 13, 'prompt_tokens': 291, 'total_tokens': 304, 'completion_time': 0.047272727, 'prompt_time': 0.018496817, 'queue_time': 0.052937633, 'total_time': 0.065769544}, 'model_name': 'llama-3.3-70b-versatile', 'system_fingerprint': 'fp_9a8b91ba77', 'finish_reason': 'tool_calls', 'logprobs': None}, id='run-b690471f-fd82-44f3-a000-265b195146af-0', tool_calls=[{'name': 'transfer_to_addition_expert', 'args': {}, 'id': 'call_jwfc', 'type': 'tool_call'}], usage_metadata={'input_tokens': 291, 'output_tokens': 13, 'total_tokens': 304}),\n",
       "  ToolMessage(content='Successfully transferred', id='cba96699-85cb-4728-ae03-c8af1384e71d', tool_call_id='call_jwfc'),\n",
       "  AIMessage(content='The result of (3 + 5) * 12 is 96.', additional_kwargs={}, response_metadata={'token_usage': {'completion_tokens': 17, 'prompt_tokens': 317, 'total_tokens': 334, 'completion_time': 0.061818182, 'prompt_time': 0.027799303, 'queue_time': 0.052287596000000006, 'total_time': 0.089617485}, 'model_name': 'llama-3.3-70b-versatile', 'system_fingerprint': 'fp_9a8b91ba77', 'finish_reason': 'stop', 'logprobs': None}, id='run-10590d1e-0425-42f0-82df-101d249d2b67-0', usage_metadata={'input_tokens': 317, 'output_tokens': 17, 'total_tokens': 334})]}"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "app.invoke({\"messages\": [(\"user\", \"what's (3 + 5) * 12. Provide me the output\")]})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6ff4dd3f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "358d91b0",
   "metadata": {},
   "source": [
    "# Supervisor Agent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "3a65a260",
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing_extensions import Literal, TypedDict\n",
    "from langchain_core.tools import tool\n",
    "from langchain_groq import ChatGroq\n",
    "from langgraph.graph import StateGraph, MessagesState, START, END\n",
    "from langgraph.types import Command\n",
    "from dotenv import load_dotenv\n",
    "from IPython.display import display, Image\n",
    "from langchain_core.messages import BaseMessage, HumanMessage\n",
    "from langgraph.prebuilt import create_react_agent\n",
    "from typing import Annotated\n",
    "from langchain_experimental.utilities import PythonREPL\n",
    "from langchain_community.tools.tavily_search import TavilySearchResults"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "b5108d65",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from dotenv import load_dotenv\n",
    "\n",
    "load_dotenv()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "da261759",
   "metadata": {},
   "outputs": [],
   "source": [
    "tavily_tool = TavilySearchResults()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "ab77b47b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'url': 'https://tradingeconomics.com/india/gdp',\n",
       "  'content': 'The Gross Domestic Product (GDP) in India was worth 3567.55 billion US dollars in 2023, according to official data from the World Bank. The GDP value of India represents 3.38 percent of the world economy. source: World Bank [...] GDP in India averaged 785.41 USD Billion from 1960 until 2023, reaching an all time high of 3567.55 USD Billion in 2023 and a record low of 37.03 USD Billion in 1960. This page provides the latest reported value for - India GDP - plus previous releases, historical high and low, short-term forecast and long-term prediction, economic calendar, survey consensus and news. India GDP - values, historical data and charts - was last updated on May of 2025. [...] GDP in India is expected to reach 3792.00 USD Billion by the end of 2025, according to Trading Economics global macro models and analysts expectations. In the long-term, the India GDP is projected to trend around 4043.00 USD Billion in 2026 and 4281.00 USD Billion in 2027, according to our econometric models.\\nUSD Billion\\n5Y10Y25YMAX\\nExport API\\nOK\\nLoading...\\n201320172021\\n|\\nWorld Bank\\nValueChgChg%\\n| Related | Last | Previous | Unit | Reference |\\n| --- | --- | --- | --- | --- |'},\n",
       " {'url': 'https://en.wikipedia.org/wiki/Economy_of_India',\n",
       "  'content': 'countryStatisticsPopulation 1,428,627,663 (1st; 2024 est.)[5]GDP $4.19 trillion (nominal; 2025 est.)[6] $17.65 trillion (PPP; 2025 est.)[6]GDP rank4th (nominal; 2025)3rd (PPP; 2025)GDP growth 7.2%\\xa0(FY2024)[7] 6.4%\\xa0(FY2025)[7]GDP per capita $2,980 (nominal; 2025 est.)[7] $12,130 (PPP; 2025 est.)[7]GDP per capita rank136th (nominal; 2025)[a]119th (PPP; 2025)[a]GDP by sectorAgriculture: 17.7%Industry: 27.6%Services: 54.7%(FY 2023–24)[8]GDP by componentPrivate final consumption: 56.3%Government'},\n",
       " {'url': 'https://timesofindia.indiatimes.com/business/india-business/in-7-charts-how-indias-gdp-has-doubled-from-2-1-trillion-to-4-2-trillion-in-just-10-years/articleshow/119545395.cms',\n",
       "  'content': \"With a healthy GDP growth rate, the Indian economy is expected to surpass Japan in 2026 as the world’s 4th largest economy. It is likely to become the third largest economy in the world in nominal GDP terms by 2028, according to IMF projections.  \\nIndia’s GDP is expected to rise to $5723.3 billion by 2028 and $6307.2 billion by 2029. In 2029, the world’s largest economy, the US, is projected to have a GDP of $35458 billion - which is 5.62 times India’s GDP! [...] India’s nominal GDP in 2015 was $2,103.6 billion. Come 2025, the IMF projects that it will reach $4,271.9 billion. That's over 100% growth in just 10 years! [...] AA\\n+Text Size\\n\\nSmall\\nMedium\\nLarge\\n\\nIndia’s nominal GDP in 2015 was $2,103.6 billion. Come 2025, the IMF projects that it will reach $4,271.9 billion. That's over 100% growth in just 10 years! How has India managed to double its GDP in just ten years? What factors have worked to propel the economy, which at one time had been infamously ranked among the ‘Fragile Five’? We take a look:\"},\n",
       " {'url': 'https://www.macrotrends.net/global-metrics/countries/ind/india/gdp-gross-domestic-product',\n",
       "  'content': 'India GDP for 2023 was 3.550 trillion US dollars, a 5.86% increase from 2022. · India GDP for 2022 was 3.353 trillion US dollars, a 5.88% increase from 2021.'},\n",
       " {'url': 'https://timesofindia.indiatimes.com/business/india-business/big-achievement-india-to-become-4th-largest-economy-in-2025-overtaking-japan-will-be-3rd-largest-by-2028/articleshow/120900272.cms',\n",
       "  'content': \"Till 2024, India was the 5th largest economy in the world, but in the ongoing year it is expected to become the fourth largest, as per the latest IMF predictions. In the coming years, India is also likely to overtake Germany to become the third largest economy. By 2028, India’s GDP is estimated to be $5,584.476 billion, more than Germany’s $5,251.928 billion. India will become a $5 trillion economy in 2027, with a GDP of $5,069.47 billion.  \\nTop 10 Largest Economies In the World 2025 [...] AA\\n+Text Size\\n\\nSmall\\nMedium\\nLarge\\n\\nAccording to the IMF's World Economic Outlook April 2025, India is projected to become the fourth largest economy globally in 2025, surpassing Japan with a nominal GDP of $4,187.017 billion. The report indicates continued growth, forecasting India to overtake Germany by 2028 and achieve a $5 trillion economy by 2027. [...] IMF has adjusted India's GDP growth forecast for 2025 to 6.2% in its report. This marks a reduction from the earlier projection of 6.5% that was published in the January outlook report.\"}]"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tavily_tool.invoke(\"gdp of india?\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "bb19ef93",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<>:13: SyntaxWarning: invalid escape sequence '\\`'\n",
      "<>:13: SyntaxWarning: invalid escape sequence '\\`'\n",
      "<>:13: SyntaxWarning: invalid escape sequence '\\`'\n",
      "<>:13: SyntaxWarning: invalid escape sequence '\\`'\n",
      "C:\\Users\\sowmy\\AppData\\Local\\Temp\\ipykernel_26596\\4245526608.py:13: SyntaxWarning: invalid escape sequence '\\`'\n",
      "  result_str = f\"Successfully executed:\\n\\`\\`\\`python\\n{code}\\n\\`\\`\\`\\nStdout: {result}\"\n",
      "C:\\Users\\sowmy\\AppData\\Local\\Temp\\ipykernel_26596\\4245526608.py:13: SyntaxWarning: invalid escape sequence '\\`'\n",
      "  result_str = f\"Successfully executed:\\n\\`\\`\\`python\\n{code}\\n\\`\\`\\`\\nStdout: {result}\"\n"
     ]
    }
   ],
   "source": [
    "@tool \n",
    "def python_repl_tool(\n",
    "    code: Annotated[str, \"The python code to execute to generate your chart.\"]\n",
    "):\n",
    "    \"\"\"Use this to execute python code and do math. If you want to see the output of a value,\n",
    "    you should print it out with `print(...)`. This is visible to the user\n",
    "    \"\"\"\n",
    "    try:\n",
    "        result = repl.run(code)\n",
    "    except BaseException as e:\n",
    "        return f\"Failed to execute. Error: {repr(e)}\"\n",
    "    \n",
    "    result_str = f\"Successfully executed:\\n\\`\\`\\`python\\n{code}\\n\\`\\`\\`\\nStdout: {result}\"\n",
    "    return result_str"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "c28632c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "repl = PythonREPL()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "6e7ea9a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "code = \"\"\" \n",
    "x = 5\n",
    "y = x * 2\n",
    "print(y)\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "dc7aaa50",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Python REPL can execute arbitrary code. Use with caution.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'10\\n'"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "repl.run(code)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "d886468b",
   "metadata": {},
   "outputs": [],
   "source": [
    "members = [\"researcher\", \"coder\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "28b85070",
   "metadata": {},
   "outputs": [],
   "source": [
    "options = members+[\"FINISH\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "05ed562a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['researcher', 'coder', 'FINISH']"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "options"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "f08fadd8",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Router(TypedDict):\n",
    "    \"\"\"Worker to route to next. If no workers needed, route to FINISH\"\"\"\n",
    "    next: Literal['researcher', 'coder', 'FINISH']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "44377fc6",
   "metadata": {},
   "outputs": [],
   "source": [
    "class State(MessagesState):\n",
    "    next: str"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "ce36ac71",
   "metadata": {},
   "outputs": [],
   "source": [
    "system_prompt = f\"\"\" \n",
    "You are a supervisor, tasked with managing a conversation between the following workers: {members}.\n",
    "Given the following user request, respond with the worker to act next.\n",
    "Each worker will perform a task and respond with their results and status.\n",
    "When finished, respond with FINISH.\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "87d34316",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'role': 'system',\n",
       "  'content': \" \\nYou are a supervisor, tasked with managing a conversation between the following workers: ['researcher', 'coder'].\\nGiven the following user request, respond with the worker to act next.\\nEach worker will perform a task and respond with their results and status.\\nWhen finished, respond with FINISH.\\n\"}]"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "[{\"role\": \"system\", \"content\": system_prompt}, ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "fd15f95b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def supervisor_node(state: State) -> Command[Literal[\"researcher\", \"coder\", \"__end__\"]]:\n",
    "    messages = [{\"role\": \"system\", \"content\": system_prompt}] + state['messages']\n",
    "    \n",
    "    response = llm.with_structured_output(Router).invoke(messages)\n",
    "    \n",
    "    goto = response['next']\n",
    "    \n",
    "    print(\"below my goto ****************\")\n",
    "    \n",
    "    print(goto)\n",
    "    \n",
    "    if goto == \"FINISH\":\n",
    "        goto = END \n",
    "    \n",
    "    return Command(goto=goto, update={\"next\": goto})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "0ff17780",
   "metadata": {},
   "outputs": [],
   "source": [
    "def research_node(state: State) -> Command[Literal[\"supervisor\"]]:\n",
    "    \n",
    "    research_agent = create_react_agent(llm, tools=[tavily_tool], prompt=\"You are a researcher. DO NOT do any math.\")\n",
    "    \n",
    "    result = research_agent.invoke(state)\n",
    "    \n",
    "    return Command(\n",
    "        update={\n",
    "            \"messages\": [\n",
    "                HumanMessage(content=result['messages'][-1].content, name=\"researcher\")\n",
    "            ]\n",
    "        },\n",
    "        goto = \"supervisor\"\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "2fedda5e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def code_node(state: State) -> Command[Literal[\"supervisor\"]]:\n",
    "    \n",
    "    code_agent = create_react_agent(llm, tools=[python_repl_tool])\n",
    "    \n",
    "    result = code_agent.invoke(state)\n",
    "    \n",
    "    return Command(\n",
    "        update={\n",
    "            \"messages\": [\n",
    "                HumanMessage(content=result[\"messages\"][-1].content, name=\"coder\")\n",
    "            ]\n",
    "        }\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "70ad57e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "graph = StateGraph(State)\n",
    "\n",
    "graph.add_node(\"supervisor\", supervisor_node)\n",
    "graph.add_node(\"researcher\", research_node)\n",
    "graph.add_node(\"coder\", code_node)\n",
    "\n",
    "graph.add_edge(START, \"supervisor\")\n",
    "\n",
    "app = graph.compile()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "17f373ae",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXoAAAD5CAIAAACmkWkFAAAQAElEQVR4nOzdB1hT1/sH8JM9CHsPUVCcKO5dwVW17tVardZf3bNubWu1WqvVOlDr3qu49xa3oCgibpG9QXYgCYSM/wvXP6UKyEq8Sd7P48NzSW4SvMn95pz33HsuW61WE4QQ0jw2QQghrcC4QQhpCcYNQkhLMG4QQlqCcYMQ0hKMG4SQlmDcVINciSotMU8qVkrECoVCrczXgWMLeAImh880MmGLTNlWjlyCkOZh3FRedoYi9El25AuJTKISGrOMTFgFe685W63SgbhRq0hydC7kI0/Aig2Rurgb1XYX1WwkJAhpDAMP86uE/Dy1/7nU7PR8C3se7Kj2Lnyiy6TZysiXEkifxMjcDn0tazUyIghpAMZNhT2/lwVZ076vVeOOpkS/pCfJ4b/G4bK+HGXLYBCEqhfGTcX4Hko2s+G27G5O9Ne72Lyj62KHzXbGmg6qXhg3FXB+Z2IdD1H9VsbEABz+K6bPWAcoRRGEqgnGTXkdWxfb1MvcrZmIGIzDq2M9B1nbu+p2ZQrRB5Ogcrh59F3DtqYGlTVg2JwaZ7fH5+epCELVAVs3n/Y6IDsnS9HqS32u15QmJ0t5+/i73mPsCUJVhq2bT7t5NLlFV0PMGiAyZRmbs5/eySQIVRnGzScEXEpv1cOCySIGC4b8/c+nEYSqDOOmLAq5Oik6t9WXFsSAsTmM9n2snt7OIghVDcZNWcKf5whE2m7YzJs379y5c6SCwsLC+vTpQzTDsbbg9UOMG1RVGDdliXohcdH6Ef2vXr0iFVe5R5WTlSM3V6rKzlAQhKoAR6bKcsw7btBURxZbI8fznzx58p9//klMTOTz+S1atJg7d665uXnbtm2pe0Ui0a1bt9LS0ry9vR89eiQWi+3s7IYNG/b1119TK3Tu3HnChAn+/v6BgYFw48GDB6nbZ82aNXz4cFLdHl5ONzJlN2pnQhCqLDxmtFSSLEVOZr6GsiYoKGj58uULFy5s2bJlZmbmhg0bfvrpp507d168ePGrr76C6OnZsyestnjxYsijVatWWVhYPHny5Pfff4fQ6dSpE9zF4XAgsDw9PcePH1+rVi2FQnHz5s1Dhw4JBAKiAXwjVlpiHkGoCjBuSiURK41MNLV9IiIioFED1RY2m+3k5LRixYrk5GS43dS04LRPoVBILUAGsVgsiBhYhtUgTQICAqi4gdvhGaZMmUI9IY/HYzAYZmZmRDOExqyEcCVBqAowbkolESuEGosbaNTAz7Fjxw4YMKBdu3a2traWlpYfr8ZkMvfu3fv48eOMjAzo9ubk5NSpU6foXnd3d6ItsCkk2Vi7QVWCpeJSqdUMDldT2we6P3v27HF2dt64cWPv3r0hd968efPBOnK5HDpK0O2Ccsz+/fuh0FM8a0hhfYdoC5PFYLFwTgpUJdi6KZWRMVOcJica4+bmtnTpUpVK9fTp0/Xr10+fPv3ChQvFV3j27BkUbnbs2NGsWTPqlqyszzYaDZUsrgC/nFCV4AeoVAXdB7GmqhXPnz+HNCGF3SVIk4kTJ6anp8M4VPF1oHUDP4vKMcHBwUlJSeQzkYoVRsb45YSqBOOmVMZmbBMLDtEMPz+/2bNn+/r6xsXFQTfq+PHjDg4OUMHhFYIOVEhIiKurKww/HTlyJDU1FQa816xZA8PkUVFRUMf5+AmNjY0hrSCSoEFENECRr7aww9m2UJVg3JSOQaD7EPlSQjQAijX9+/f39vYeMmTItGnT4BYYC2cUTtg5evToa9euTZ482cjIaNGiRRBMsCYUepYsWTJ8+HCIJ7jr4yeEgXNHR0doJZ05c4ZowKsHWU5uOHE6qhI8zK8sLx+Ik6Nzu3xjQwxbZkr+ue0JI3+pSRCqAmzdlMWlkUgqxoNNSHyYrEEbPJ4YVRUW/8oiNGYaW7Cf38sq7aILCoWiW7duJd4FhV4ut+RiB4xn79y5k2jGgQMHdu3aVeJdJiYmYrG4xLs6duy4bNkyUoo7J1PGL3clCFUNdqY+IV+u3vVrxMSVtUu8F7ZeaaVZiUQiEAhg4Onju6AAbG1tTTQjJyentEwpIwH5fL6FRcnzbDy8nA4/W/c06Fk4ULXAuPm04JuZTDajyRf6dlWp8lAqybnt8QMmORKEqgxrN5/WtLNZ9BtJ1CspMTyHV0V7DjL0SjmqLhg35dJ3nMOtY+8ykjV4kDENnd2W0LqXpbmtpg4+QoYGO1PlBdvJZ1WM1xBrh9oameGBbmDku3VPS1tnHkGommDcVMzJjXENWps2aKPPF9KU5aiOecd07G/t2ljbMxki/YZxU2EPLqZFPJd06GtVs6G+HWWrkKv9zqWmJ8m7DrMxscQ+FKpmGDeVkZYo9z+XKhCxbGvyXd2NjEx1/vCl2LeyhHDZk5sZ7ftaGeYYHNICjJvKS4zIDQnKjnyRY27DFZmxjUzYQhOWyJStyNeBTcpkMrLS8iViBSy88M+yd+W7eYgatcegQRqEcVMNUuLy0hLksOvCP9ikedLqPO8hIyMjJibGw8ODVCuBCYvNZkBEGltwargJWBycOgtpHJ7EUA2snXjwj2jGw4fRN1+dmvPdlwQhHYdxgxDSEowbhJCWYNwghLQE4wYhpCUYNwghLcG4QQhpCcYNQkhLMG4QQlqCcYMQ0hKMG4SQlmDcIIS0BOMGIaQlGDcIIS3BuEEIaQnGDUJISzBuEEJagnGDENISjBuEkJZg3CCEtATjBiGkJRg3CCEtwbhBCGkJxg1CSEswbuiOwWCIRCKCkO7DuKE7tVqdk5NDENJ9GDcIIS3BuEEIaQnGDUJISzBuEEJagnGDENISjBuEkJZg3CCEtATjBiGkJRg3CCEtwbhBCGkJxg1CSEswbhBCWoJxgxDSEowbhJCWYNwghLSEoVarCaKf/v37x8XFkcLptYq/R48fPyYI6SYmQbQ0dOhQPp8PWUMKE4dSr149gpDOwrihqUGDBtWoUaP4LTwer1+/fgQhnYVxQ1NCobBXr14sFqvoFicnpyFDhhCEdBbGDX1BuDg7O1PL0LQZPHgwm42lfaTDMG7oy8jIqHfv3lTEODo6YtMG6TqMG1qDiIGggaYNVI6ZTHyzkG7DxvmH8mSqtIQ8cbpCka8iNNCrw/jAwMC6dl1f+GcRGhCI2FYOXFMrDkGogvC4m/94+UAcGpSTL1fZ1hLmSpQEfUSpUL2LyTW34fQd58DA9haqCIybf70JzAkNyvb6xp6gT4kPkz6/mz5gsiOHyyAIlQ9+Pb0X+ULy5iFmTXk51hE272p1Zks8QajcMG7eC76d2bqXFUHlZuPMF5lxol9JCULlg3FTQK0iCeEyYwssf1aMwJidEp9HECofjJsCOZkKCzseQRVkbM6RZmNBHZUXDoS/lyfD3abCVCq1SolDDai8MG4QQlqCcYMQ0hKMG4SQlmDcIIS0BOMGIaQlGDcIIS3BuEEIaQnGDUJISzBuEEJagnGDENISjBuEkJbgKZp6YuGi2fPmTyUI0Ri2bvREv75DVEo8yxTRGsaNnmjdqh1BiN4wbiopOTlp85a1T58FyWRSe3vHoUNG9P5qANwOPRoWm73iD29qtctXzq1cteTyRT8ej/fTLzO4HG6DBu6nTh/Jysp0dXWbOeMntzrvL/t99eqFEyd9YmKjhEKjLp17jPlhMp/Ph9v79e88+vsJAY/8g4MD+/QedPXq+VMnfYuub+dzeN++/dtPHr+2/M9f5Xl5q1b+DTc+fRq0a8/miIhQtVpdu3bdcWOmNm7cFG6Xy+W7dm++cfNKZmaGpaVV1y49/zd6IjxVeHjo2PHfLl+2buv29UKBcMvm/QQhDcDaTSWtXPVbRmb6nys27N51dOCAb9Z5rwh68qjsh3DYnKCgh8nJifv3njx65JKR0GjRojkqVcHlZW7d9l2xcnGrVu3g2RbMX3L7jq/3hj+pR7E5nHMXTkIqea/d3q1rzxxJzpPgwKLnvHPneru2XwiFwqJbZDLZzwtnuLrU2bRxL/yDhfk/TcvJyYG74I+E+Js6Zc6BfafGj5t++szRrdvWF/xhnIJpDPcf2DF82Oh5cxcThDQD46aSIqPC27TuUL9eQ0cHp/79hmzcsBt27LIfwmAwlCrlxAkzoKVjYmzy/ajxScmJL148hbt8fPZ6eDQfO2aKvZ1Dq5ZtoT1y5cr5tLRUuIvFYvF5fLgLmkXwz8nJ2c/vFvWE0MJ6E/IKGinFX+XduySpVNq921c1a7rUquUK4bJyxUZowkB76uq1C6NGjvPs1NXOzr5L5y8hJS9eOq1QKJiFVyL38GjRo0cfF5faBCHNwLipJGhTHDy0a8tW7+Dgx7DHNqjfyMzM/JOPqunsAllDLdeqVbBjx8XHwMNDw0Jatfy3+AJ7PvwMjwilfoWUKboLYuKe3y3qcj137l43Fhm3adOh+EtAHsG/3//4+R+fvRERYRA00JOCfhk8G7Sk3N09itasX68RNIUSEuI+fhWENAFrN5UEZZc6tete87149NhBY2OTgQO+hoYDq7CZUAaB4N9eD1WaycnJluXKID727N0KVZjiK6enp1ILRkaiohs7e325/8DOV6+eN2rU5Pad6506daW6QkXgb9jgvfPI0QMXL57esfNvaHyNGTOls1d3qVQC9wqL/QGCwi6YVCYViYw/eBWENAHjppJgJx80aBj8g7LrpctnoQRramIGv0KPqfhqeXn/uVABtc9TJIXLEFUCvoDJZEKxuVfPfsVXNrew/Ph1oX8E/Z27927a2tq/fPnsh/9N+ngdc3OLiRN+hH8xMVHQxln6+081nGpSaQKlnw/+GBGmDNIW7ExVRm5u7jXfS9AJgmXoQ3077Pv69RtBhwh+hZaCpNguHR7+tvgDoeKTJX5/qe+3b1/DTwgC6O/UdasPNRdn51rUPzs7B6gQGxc2Oj4GDZwHAffu3L0Bo0tNC7tdxcUnxN27d4tahqeaNfNnSED4M2AgDBo+r14+K1oT0grCzsHBiSCkFRg3leS9fsXqtcvehr5JSIy/fuMK7M9Q64Xb69VrGBLyCoom0D8KeOgfGPig+KMgjFav/j0qKiLk7eut27wdHWtAnwhuHzbsexicgpZIbGw0POfyFb9O/3EMFFZKfOnOnb+Mjo6EKi/kDjSLPrg3KSlh8ZJ50JmCpg0826F/dkPKNGzY2NTEtGePvgcO7fLzuw01ZihFnzl7bMjg4R8/A0Iagp2pyoCyy+pVm6EyMmv2BGjjQGMEOjWwM5PCo3shL36cMRaGe1q3ajdu3DToy8A6VIW4tqtby5ZtF/w8HUad3Nzq/750DdX5gtGinxYs9Tm8Fyo40Otp7N503ZptAoGgxFd3cqwBrSF4lTmzf/343hbNW8+bs+jo8YPwVNBugoI0vEqNGjXhrh+nz4cnX7d+BXQAbW3soNg07JtRBCFtYVBjHAYuO11xYmPc4Bm1iCYt/m0eFIbXrN5C9EVIYFZOutxrqDVBqBywdYMQ0hKMG4SQlmDcXkcOXQAAEABJREFUaM+S31YRhAwYxg1CSEswbhBCWoJxgxDSEowbhJCW4BGlqEp8fX2nTZumVqupiXsQKgPGDaqSrl27fvvttxA3crm8W7duq1evhhvz8/MJQh/BuEFVwmAw2rdvz2Qy+Xz+sWPHWrVqBTfGxcX179//4MGDsEydyIoQwbhB1cjc3NzT0xMWXFxcNm3aVLNmwYlafn5+I0eOvHHjBkEGD0vFSCOcCsECBJC1tXVGRgYs79u37/79+1OmTGncuDFBhgfjBmlcw4YNqYXvv/8elqnKzpo1a5KTk6dPn06lEjIEGDcF2FyGkQluiopTM4TGrAo9girugKlTp967d4+6RMQvv/zC4XBmz55tbGxMkP7C2k0BgYiVk6WQirGoWTHJ0VJzGy6pFB6PB6Na9evXh+W5c+e2aNFCIimYzBSG1deuXYsFZr2E8928F3Apnclh1W9lSlD5wAfn9N/RvcaLZLkSmUyWm5sLP/MKQZtl0KBBpFKioqKgugwP53K5EydO/OKLL0aNwjnA9ATGzb/O7UisUVdUuym258vF92BCm14WP84fSQpHu4FKpVIqlXK5HBIHwuLmzZukaoKCgp4/fw4Vn+jo6HXr1vXu3bt79+4E6SyMm2LU5Oz2BDMbPk/ItHTkq/LxMNkS5OWq0uJz3zzMGjjF0bYmf+fOnXv27PngghPwoXr8+DGpPvCEUOiJjY0dPnx4YGDgmTNnBg4c2Lx5c4J0CsbNh0Kf5CRF5cpzVYmxmXFxcW5ubpqePBwGaKBFUKNGjRLvhU5KVlaWra0toQdjc46FHadpJzMm+/0lbn777beLFy8WP4lBKBTeuXOHaAZsK19fXwg4SJxLly49ffr0m2++cXFxIYj2MG5KEBkZCR/f48eP9+rVy8jIiGjSH3/8cfnyZciaf/75p8QVHj58CM2HLVtoPcPx2LFjg4ODqWX4RJ04caJWrVpE87Kzs2HrwXhWz549fXx8MjMzv/76a0tLS4JoCUem/gO+OSdPnkx1BIYMGaLprIGh3/Pnz1MV1tLWadiwIaxG6A26VEWtMxjSdnBwgIWOHTseOnSIaBIEzdChQyFrYNnLywteOiSk4GpfW7du3bdvX2lXzkGfC8bNe/DRhPEU6NdAYRKChmjeyJEjb9++TR3zBjEHPaYSVxOJRHXq1CG0B6VcKmXs7OygTgwLUCoWFl4X+NWrVy9evCAaZm9vD42s9u3bk4JLcXWG7RkTEwPL3t7ep0+fhho2QZ8bxk2BGzduwJAHm82Gr+g2bdoQDYNQ69u378uXL4tugZ2htLh5/fr12rVrCe1B72nu3LkQjrBvU7dAWwPKK7BgbW29evXqU6dOEW2pV6/e9OnT4ScswxsKYQfdLlj+888/8eytz8jQ4wYKjfATypww8MHn84lWjBkzJjExsXgFmsFglBY3sJ+EhoYSXfDFF1/cunXr49shbvbu3duuXTtSuMNDN0ebFUN43YULF5qZmcFyo0aNqBp2enr6+vXrnz17RpAWGW7cQO8Jyoow9gTL3bp1I1oEuWZiYlL8FqjdUMfUfkwnajflAZ0s+DllyhQIVijGwzIMbBPtgkYljKPBAmx/c3Pzc+fOwTKUe6D2FB0dTZCGGeLIVFRUFHzXUQe/1q5dm3wmUqkUPv1isRjeAoFAsGjRIkM7hm3AgAFt27ZdsGAB+azgY3DgwAGFQjFt2rSAgADIHXgjIIwIqm4GFzdnz57dv38/jDpT5czPCEZPWCzWuHHj+vfvn5qa6ufnV+JqUGe9cOEClEWIPgoKCmrevDn831NSUiB9yOcGnVz4eEBDDEYMoNQNTeAuXbporZet9wyoMwXVGfgJoyfHjx//7FkDXF1dqbOBzpw5U1rWkMLv3oiICKKnqCODPTw8nj9/Dvs5LJfWqdQOGN6aP38+ZA21fP/+/evXr8Py+fPn7969iwepVZFBtG7gE9ynT5/Fixd7eXkRXQNxA9/8hnDUbH5+PgxmQacSKve//vorj8cjtOHv73/06NHvvvuuZcuWJ0+ehGE4PIWiEvQ8bh4+fAg7KvRZYJD7g+rs5wUDwz179nR3dyfoI5cuXWratKmNjc3t27ehL0NoBkb0L168CN9eTk5Ox44dgz/Vzc2NoHLQ587UoUOH9uzZAzU/CwsLWmVNQkIC7EjlzBqo3fz111/EkPTq1Qs6MvAlAbkD5VtSeGIEoY2BAwfu2LGDmoQQGp7QECOFp7ZBpxh+Jah0eti6gTfe19cXek+hoaH0/NqBv5AUDoeXZ2WdOGdKc9LS0iwtLS9fvgzFnUmTJolEIkJLMLC1fPnyuLi47du3JyUlvXz5skOHDlhj/oC+xQ1UOnr06LFhw4YWLVoQusrKyoLWFoPBKM/KhlO7Kdvhw4ehRzxkyJCwsDCan9WRmZkJ0QMLq1atgu88+LVoylQDpz9xA6PFzZo1My5EaOzq1aswwrpixQqCKmXTpk0wSLR7927qhCyai4yMXLlyJZSWFyxY8PTpU6iFF00Ub4D0pHYDfemAgAA7Ozv6z6395MkTapy1nAywdlO2KVOm/P7773K5XCaTwftO89O+oVm6detW6lBGGHqDr5kjR47AcmBgIHVEu0HR7biJjY2lLtXYt2/fpUuXanoerGoxf/58aj7wctLv424qB0pyZmZmAoFAqVRSZ3hQZ2DSHAyiHzhwgJrFGeo7U6dOffDgASksz6WnpxMDoKudKfizpVLpiBEjoKVKnfirE968ecPlcl1dXcv/EKzdlAeM9Pn4+CxcuFC3rloFgwZQTt61axdUpmBAAP54aPXAyDpUqYg+0sm4gTemS5cutra2Olf59/T0hBoTbYdXdBrsqBDNXl5et27d0sXjOaF7CF9FixYtunLlip+fH4wkwGAcRA/RI7rXmVq/fr1EIqlZs6bOZU14ePiSJUsqmjVYuykn6KpQKQNj5zASBNGjW1+l1Ik1UBOAKiSUBeCP37hxI1QJSOFQpn50qHWmdRMUFOTv7w/dXcgaTc/pSSsGftxN5ahUKuinwE/I9/Hjx+vuUb9Ukyc1NXXSpEnOzs7UlY4hjKytrYkO0oHWjUKhgIiB/Y2qselo1kD9Zd26daTiYNx03rx5BFUE7JAwTA4NyV69ep08eZJ8jrl1qgXV5LGysjp27Bh1+HJGRsbIkSP//vtvWIaxLd2aj5nWcQNBA5XghIQE2Ogw5ElNhauj9u3bR80vVVGwz2CduNKgxgdDgaRwZolu3bq9fv2a6CxqQkIY1rx8+fKwYcNI4UE93bt3P3/+PCmMHkJ7tI4bKNPAngZtSA6HQ3Rc//79qY9IRb18+XLZsmUEVU3r1q2hgUBNkH7w4EFdn7sP2jukcLbWe/fuwX8Nlu/evQsLjx49IjRG09qNno3+wvdPnz59SKVAR3LmzJnbt28nqJps27atWbNm1F6qTyBMoasFzRxo9VCT0tMNTVs3MApYoUNv6WzUqFF169YllQW1KiprwsLCCKqyvLy8rl276l/WABaLBa0eqFJRE/7TEE3jBvYx+ExAEZ7oMrFYDD8XLVpUlbgpAlvD29uboCqAIiubzdaJ63ZVGjTcoOdOaAkv2qspd+7cgSJ35eo1pYGiw+DBgwUCAUEVB11aV1dXQz5D8rOjb9zEx8fL5XIdLd9AL3rOnDmVG/kuG4zWXbt2rXPnzjiXSvlRFymFJrNOnEReRcHBwVi7qbCkpCQdnaXhwYMHEOKayBoAfQFPT0/oaVJX+0WflJubC1sMihqGkDWk8AgjrN1UWOPGjXXxQBuoDtja2mr0FDvYbfz8/ODrOjExkaAyQWHY39///v375ZzMTA9g7cYgwLeoVCqFRpnWqgMvXry4ffv2lClTCCpJQECAo6Ojbp0jrt9ofZifDk1BBJ/se/fumZuba7MS6e7uDmVjKEgT9JHU1NR9+/YZYNZA7ebUqVOElmgdN2/fvqWmPqM5GPCGT3a3bt2032L/4YcfTExM4BNGUDGphTZv3kwMD9ZuKqlTp0729vaE3iATYbToM36yRSJRvXr1WrZsSV3gAW3atAnekQpNmahP6Fy7oXXcQEt4+PDhhMbGjRsHe7uFhQX5rKBLBR3P8PBwqB8TwxYdHQ1bo3Jnw+oH2GsgcQgt0b1UfPr0aS8vL+pcWFqB78/Q0FCZTEari7fGxMRcvXp17NixxCC9efPGqhAxYHjcTeUFBQXBoC+hmcePH798+dLNzY1uF4p2dnbOz88PCQkhhgdC1sbGxsCzhtC7dkP31g3s1dnZ2W3btiW0AUPdixYtovMp2u/evZPL5QY1KBMVFZWRkUHbToQ2wWBuenp6kyZNCP3gcTcVk5KSAvFXoUspfBZ5eXldunS5fv26IZzrcPPmzQ4dOlAT3yE6o3tnCkok1DyJdDB16lQ2m03/rAE8Hg+y5v79+9DMIfpLpVLBkFzHjh0xa4o8efKEmi+VhugeN7B7HzhwAKrFrVu3btGiBezw5HOANuCdO3dGjBhhbm5OdAS0azp37iyVSg8dOlT89l69ehG9IBaLodsIQ3J6MNljNYLO1LNnzwgt0ffqWRAuRUfN5eTkkMI5tz7LrEgvXryAAiS8tC52TGBQLzk5GfZJaAXAr1999VVqauqmTZt0/dQH+B9B3ECHkaD/ggJWzZo1CS3Rt3UDX8IfXITXwsICMohoV3R09F9//WVnZ6e7RZBZs2bBpsvNze3Tpw80B6Cldu3aNZ3uZMHo244dOzBrSgRDBPSsExM6x82yZctgpBk650W3mJiYNGrUiGgRFFyhNrxv3z6i46De9N1338GYGvUr/Keo6ft1EQzzQ1Zu27aNoJJg7aaSVq1aVXwOCi3P+Thz5kzovlF9ED1Q/DKM0NI5e/Ys0UHQqKEmyiKoFHSu3dA6bhwdHadPn04dUgxDD+3btyfacurUqYEDB+rNeIenp2fxninEKHwo/f39iU6Bpq5SqdTLWc2rEdRuqAtA0hDdR6a+/PLLfv36wdCDpaWlh4cH0Tzqggddu3bt1KkT0RfQLYXsFolEULih+qeZmZmnT58mugPqTZCSEydOJKhMdK7dfHpkKl+uTk/Ik2QryWfSp/OYqJcyGNBViq0inkuIJiUmJh48eHDu3LmEsFJJBV6Lw2VY2PGMTFmElnbu3AmFm7dv38Io26NHj1LepTAUosQwhd/VMPqfcw927doFY2qRL6QcHtPKgSsQ0XQ70wHUbiIjI+nZwPnEUcV3TqaGPsk2seDwhAbxBlNXgCcVJzRhx7zOsanB9xpqLTKj7+EFIDQ45+ntjBxxvrk9g6HUjeE2hUJBzcfKN2LFvJE4uAq6Dbfh8nXgCvdaM3jw4KioKNidodcMDVjqp7W19ZUrVwhtlBU3l/clm9nyGrWj3dnYtCVOy7/hkzBoqhNtmzlhTyUv/LO6DHNg6PKumhqX5382efB0J74RJs57UPtfuXIljKUWv7Fv376LFy8mtFHqu3XtUPfI+0UAAA+4SURBVLKlowCzpkJMLDn9JtXcuzSS0FLUK+mzu1ldh+t21gArJ173kY7/rNTt63xXLyhxfnBSrq2t7ahRowidlPy5S4rOy89T129lQlAFMVmkbW+bgMvphH6Cb2d26G9L9ILAmNWwrXnwrUyC/t93331XVAqAXkvLli3pdpm2kuMmPTGPxcFmaiUZW3ASwmWEZqDknxQpE5roTw1OaMpOisb5Uv8FXaeiBg40bUaPHk1opuRMkYiVZtY8girFxIKrVNBuWg9xer6ti15d1w1iXSHH6VP+Axo4PF7BntumTRsaXoG25LhRKdX58s828q3r1Cq1JEtBaIZBiDRLry68CdtZmoOf0v+ACo6zs7OVldXIkSMJ/dB6yBYhfQV926iXEugM5mQqJFlKDp8Jw5qkOni6LpLn5fkdZvuRGFJlXC6LMNVGJiyRGdvakVezgbAqx3lg3CCkVW+Dcp7dy0qJzTWzN+IIuGyeUGDFYvNYvGq6nIc1qU7QKFYqVPl5irQ0Zeo7uf+FNKGI5d7O1MPTlFQcxg1CWhLxXHLvTKrQXMi3MG3gpluXpnlfybVyMZeJ5RFvc/3OhbfvY9nUq2IHymDcIKQNF3YlZ6Qpbevb8ox0e+5BgQkX/pnaG4c8TQ97ltB3nD1PUN6Lx+JoN0KaBQMve5dEq7lCp8Y6nzVFmCyGbV1L0xpWuxdFJEaW97APjBuENEiZrz74Z6yDu53ISq+OQqBw+KwGXWpd3p8iTi/XUCzGDUIatPPXSMfG9lyhPlctXFo7ntgYn5706eloMW4Q0pSj6+JqeNgawgH6Lq2d/ln56XF3jBuENCLwWgbPxEhopv+XFaS4tnG4uCep7HUwbhCqfvl56kfX0k0dDOgkZ6EpLyNFGf1aWsY6GDcIVb+7Z1Ls3KrpuD3dYVnL4u7p1DJWMJS4WbZ84bQfxxCkXddvXOnctWV2TjYxJHKZOi40z9yJpk0bsTh1zq9tXry+Taob35jL5vPKaOBg6wahahb5KofNN9DrCHONeGFPc0q7F+MGoWoW9lRiZKGHR9mUh7G1MPJFqdcUqLbDAfr17zz6+wkBj/yDgwNPHLsqEomuXr1w4qRPTGyUUGjUpXOPMT9Mpq57m5yctHnL2qfPgmQyqb2949AhI3p/NYB6ktIekp6etmWb95Mnj7KzxTY2doMGDhs44OvSXvfS5bOHj+xPSkqws3P45uuRX/XqT63JYrFu37m+Y+ffycmJzs615s5ZVL9ew7Jft+jJY6Ijff45RwxPaRvzwsXTR48dTEiIgy3WulW7iRNmWFpakcI5zDdtXuPre0mlVrVr18mjSfOip4K79u7bdufuDdj+8CYOGTy8f78h1F3F38QL5+5Qs6DrLolYZV1HU3EDXaFzVzZERgdLpJn2tm5ffTm5jkvBlawTk8PW/D1iwui/79z3iY55zmSxm7p379drBnV9sfsPT16/szdHklHDsWGPLuOJxnD4LFMbQVqi3NK+hEsMVNv7yuZwzl042aG95+hR42FfvXXbd8XKxSOG/++331bFxcX8tXppdo54wbzfYM2Vq35TKBV/rthgbGwSGPhgnfcKCJ3mzVqV8ZA/Vy5OSk5csniVmbnF8+dP/lr9u62NXfv2nUp83dVrlk2c8GOzpq2CnwbCmiKRcacvCi4m/S456eLF0z8vWKpSqdatXwHPuXf3Mbi9jNctenIIIGJ4StuYV66cX7P2j/HjpnXq1DUtNWX12mU//zJj65YDDAbjH5+95y+cmjNrYROP5o8e3T94aFfRs/29afWVq+dnz1rYqFETeN83bFzF4/F69uhL/vsmwrcC0WX5cnVavMymXnlPI6oQpVK5Y/+P8vzc4UOWGIss/QKO7dw/Y+ak/bY2LixmQfft9MW1Q/rNr+XsERr+aPu+aS41PTzcu0ZEPTlxbqVnhxHtWg1KS487d3kD0aQ8mVKSpdBs3MCnhM/jjx0zhfrVx2evh0dz6ld7O4dxY6Yu/3MR/ITvwMiocPhmo1oWjv2G1K3bAFYo+yEzZvzEYrJsbQtOonV0cDp2/FBgUAAVNx+87pEj+zt28IIWEym4yG9daBalpqZQd6VnpG3ZvN/UtOAcVmgfwY4klUqFQmEZr/vBkxua0jbmsROH4PZh3xRMu+1g7zh1ypx586e+fv2iYcPGV69dgLt69OgDd/XrO/jZsyCoFsOyOFsMDSLI9G5de8KvffsMevPmpc/hfVTc6NN2looVXIGmEjMk9D60Yib+b7NrrWbwa79eM9+E3r/34OjgfvOpVkxT924uNZvCQt06rc3N7GLjXkHcPA6+BNn0VfcpsJ2tLJ3SMxNPnP2TaAyby5KISz6noTprNw0auFML0GwODQtp1bJd0V0eHgXtvfCIUPjZru0X8KW3Zat3cPBjWLNB/UZmZuZlP4TJYPoc3jv6h6EDBnXrP7BrdHSkWJz18euq1Wp4kqJfAXwDDxr4DbXsXKMWlTXAxKRgtg6JJKfs1y3+5IamtI0JWywiIszd/d8rmjaoX7BOWPjb/Pz8+PhYCJ2iu5r8f2cqLCwEHlh8Ozf1aBETE1V0oRK92c4SsVJkoamJd2PjX7FYnNou77cqRAzkTnzi26IVHOzrFi3z+cay3IIxweSUqBpODYuajVRUaQ5HyJXLVCXeVZ2dZCMjEbUgy5XBh3XP3q379m8vvkJ6esGY/MwZP9WpXfea70Xo/EN/Cqowo0aOK+Mhcrl85qzxfIFg8qRZNWrUhGbOwl9nlfi6BVfaVCoFgpK7zTz+v8d3QrOfFO5RZf+pxZ/c0EAQlLgxqS1W/HaBQFBwu0wKd5GCT7mg2F3vV5NKC8qHM2aNp7Y8Kdz4pLDJSbVt9WY7c7gMmVhTk7TKcnOUyvwFS74oukWlUpqa2Pz76uz/JJ2aFGzkvDyJuem/V+DgcTVbxs6XKRjMkgNXIzU5AV8AuQuN8F49+xW/3dzCEn5yOJxBg4bBv8zMDKhE7tq92dTErF+/IaU95OWrZ1C4Wb9uR5Mm71NZnJ1V4usaGRnBk0M5mVTTn2rIoBBW4sakthg0DItukRRGCeQFdIhgITf33+kIcv7/iBsqTRb+8odLrdrFn83Ksnonn/v8jEzY8lxNzaAsEBhzOfwZk/YVv5HJ/ETfjcsV5OX/+6ZQTR7NUeYrS7vgh0biBkYW6rrVf/cuCQaAqFughZKalmIsMs7OyX7w4F5nr+6wDvShvh32vZ//bWi0l/EQWIBfi/pBz58Hw9hW41Ka3nXq1IN6ARnxA/Wr9/o/Yd+YPm1eJf5UYvBK25jQOH358lnRaq8Kl+vVa8jlcu1s7UNCXhXdFRT0sOipYFNnZWUWbWf4smEwmZBoRL/AniaXaSpuYFwJ6sTQYrG1rkXdkp6RAHWZsh9lben8NjwAmpNU0zIs4hHRJEWeAjK3xLs0ddzNsGHfw7gGjFPExka/DX2zfMWv038cI5MVRKz3+hUwlgE3JiTGQx0xPPwtVGrLeAh8uOFDeer0kbS01ICH/jDO2qplW+j2w+e1hNf9ZtSjwAfQOXoT8urECZ+z505QtZjK/akGrrSNOXTod/AlAQX7pKTEJ8GBGzethoFFtzr14K4uXXrAUDdUhaG+c+ToAXhzqaeC+Iby8O49W27eugbvOzxq9txJMAhI9JF1DUFetkb6U/XqtHGwq+tzfHFY5GMImqBnV9ZuHnn/0cmyH9XMo4c4OxUGpKDM/OzFjcAnl4gmKeRKK3stdqaAZ6euPy1YCvVd+LBCQ7qxe9N1a7ZRnfzVqzbv2Pn3rNkToHZoZ+fww/8mUcMTpT0EzJ2zaPfuzZevnIOv0AXzlyS/S1r2x89z5k3eud3ng9eFYdrZs36BDzqMesCTwzI8baX/VANX2saE0aW8vFwovW3fsRG2GAxFTZwwg3oIlOHga2DL1nUqlQrGBMaPn75k6QKlomCcAkpvUKrbtn09fG1YWFjCsPfYMVOJPnKux4+LklgbV/8Fr1ks9rjv15+/vGH/4Z/kcpmFmcOXncd2av9t2Y+CkOrb88fbfodg4NzJof7XA35et2WUUqmRaxNJ0nNNLDgcfsnHATCoit0HAi6l5+cTD0+DO8esWuRkKK7uj/t+US1CJ+lJ8kt7k/pNcib6IiUuN/Bq6tcznQjNvIvJu7jvXa2WDsTwvAtLc2vMaeZlXuK9eBIDQtXMxplnZMLKlxniJfcUufn1mpV6bipeiQGh6tfcy+Shb5p9Q5vSVlj4R8l9fBjYZjJYpJRjkn+ZfUbAr7YjBvYcmhseFVTiXUpFPotdQhUfBtF/nVvq2TzpsVmOLlyhaakjZRg3CFW/2h6ih1czZFl5AtOSi6azJh8o8XaFQs5ksqlDhD9WvYfMDO63QKHIK/EuWW5OibnGYJTVH0oMSR+wqnYZK2DcIKQR3b61uXk8XWBacgPHwvzzV3ZMjKvz4LKMmIxOg6yZrLJOFsPaDUIaYe3Ea9LBKDkkhRiArIRsYxNV4w6fuJIvxg1CmlK/lUkdd15SSBrRa+lx2WxGLrTmPrkmxg1CGtSim3n9Zlw9buNkxmepZZLeP5TrkudYu0FIs5p6mvEE4uC7yeY1zPnGXKIvlPkqcWKWuaXaa6xjOR+CcYOQxjVobWLtyL9yIInJ4VjXtmTzdHsKMZASkZ4em915qE3dFhUYmMe4QUgbrBy5IxY4hwblBN1KkeepBeZCExsjrkCXdkCVUi1OlkjTJUymuk4T4dAprqSCMG4Q0h635iL4Fx8mC38miXiRlCtRcgUsDp8lNOXKpXQ8CpnFZuTnKvPzlHKZwsiMa2XPadzDtHZjI1KpyVExbhDSNsc6AvjXaZBVnkwlFSul2Qp5rkqpUBP6YTAZHB5DaMw2MmEJRFXtA2LcIPTZ8ARM+GduaygXpSo5bnhCplpKUOWoVcTCXlOz1VYak8UwNterbxeVmphZG+jV43RUycfdmFlzk6IwbyopJUHG5dHugCbYMxMiZAo5HVvslZMWlysw0vkhHoNS8l5Ro64AilhqFUGVkBafW7uJEaGf+q1MEyP1Z5bCjHd5Lo3ouJ1RaUqOGyhHd+xv5XswnqAKCvJN43AZdZrS8boCXkOsAq+mZL6TE90XcCHFwpbjVBcnXdQlJc/mR0mOyTu7Nb6Jl4W5Da/qRWn9Bi3B1PjcrBQ5k6X2HEzfqwso8tU+q2LqtzITGLMsbHlKlY71rVRKkhInS43NtXLktuxuTpBOKStuQK5U9eRmxruYvJwsjcxsqjcs7XhcAaNWAyNXWnajPvD0ThbUcVQKkpmqYy0dCzsu1Gtqe4hqYLtGB30ibhBCqLrgcTcIIS3BuEEIaQnGDUJISzBuEEJagnGDENISjBuEkJZg3CCEtOT/AAAA///M+5MoAAAABklEQVQDACIgD9yM6cgLAAAAAElFTkSuQmCC",
      "text/plain": [
       "<IPython.core.display.Image object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "display(Image(app.get_graph().draw_mermaid_png()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "c0b510ff",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "below my goto ****************\n",
      "coder\n",
      "((), {'supervisor': {'next': 'coder'}})\n",
      "----\n",
      "(('coder:0c4bd30d-6f20-d99f-fe45-601da36e8d6c',), {'agent': {'messages': [AIMessage(content='', additional_kwargs={'tool_calls': [{'id': 'call_ptmf', 'function': {'arguments': '{\"code\": \"print(42 ** 2)\"}', 'name': 'python_repl_tool'}, 'type': 'function'}]}, response_metadata={'token_usage': {'completion_tokens': 22, 'prompt_tokens': 301, 'total_tokens': 323, 'completion_time': 0.08, 'prompt_time': 0.021251666, 'queue_time': 0.065031934, 'total_time': 0.101251666}, 'model_name': 'llama-3.3-70b-versatile', 'system_fingerprint': 'fp_9a8b91ba77', 'finish_reason': 'tool_calls', 'logprobs': None}, id='run-146e57ea-e8a5-4ac2-bd5e-32faf73da07f-0', tool_calls=[{'name': 'python_repl_tool', 'args': {'code': 'print(42 ** 2)'}, 'id': 'call_ptmf', 'type': 'tool_call'}], usage_metadata={'input_tokens': 301, 'output_tokens': 22, 'total_tokens': 323})]}})\n",
      "----\n",
      "(('coder:0c4bd30d-6f20-d99f-fe45-601da36e8d6c',), {'tools': {'messages': [ToolMessage(content='Successfully executed:\\n\\\\`\\\\`\\\\`python\\nprint(42 ** 2)\\n\\\\`\\\\`\\\\`\\nStdout: 1764\\n', name='python_repl_tool', id='fc7b3381-fca8-491a-9094-f5603896d025', tool_call_id='call_ptmf')]}})\n",
      "----\n",
      "(('coder:0c4bd30d-6f20-d99f-fe45-601da36e8d6c',), {'agent': {'messages': [AIMessage(content='The square of 42 is 1764.', additional_kwargs={}, response_metadata={'token_usage': {'completion_tokens': 11, 'prompt_tokens': 360, 'total_tokens': 371, 'completion_time': 0.04, 'prompt_time': 0.047555895, 'queue_time': 0.054716506, 'total_time': 0.087555895}, 'model_name': 'llama-3.3-70b-versatile', 'system_fingerprint': 'fp_3f3b593e33', 'finish_reason': 'stop', 'logprobs': None}, id='run-d00411fa-3d9f-4435-87f9-c32ef5db4992-0', usage_metadata={'input_tokens': 360, 'output_tokens': 11, 'total_tokens': 371})]}})\n",
      "----\n",
      "((), {'coder': {'messages': [HumanMessage(content='The square of 42 is 1764.', additional_kwargs={}, response_metadata={}, name='coder')]}})\n",
      "----\n"
     ]
    }
   ],
   "source": [
    "for s in app.stream({\"messages\": [(\"user\", \"what's the square of 42?\")]}, subgraphs=True):\n",
    "    print(s)\n",
    "    print(\"----\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cbe571f9",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "langgraph",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
