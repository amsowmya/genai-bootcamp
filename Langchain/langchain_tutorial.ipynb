{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from dotenv import load_dotenv\n",
    "\n",
    "load_dotenv()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os \n",
    "\n",
    "os.environ['HF_TOKEN'] = os.getenv('HF_TOKEN')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_openai import AzureChatOpenAI\n",
    "from langchain_google_genai import ChatGoogleGenerativeAI\n",
    "from langchain_groq.chat_models import ChatGroq\n",
    "from langchain_huggingface import  ChatHuggingFace, HuggingFaceEndpoint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\2260927\\AppData\\Local\\anaconda3\\envs\\langchain\\Lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n",
      "Note: Environment variable`HF_TOKEN` is set and is the current active token independently from the token you've just configured.\n"
     ]
    }
   ],
   "source": [
    "llm = HuggingFaceEndpoint(repo_id=\"TinyLlama/TinyLlama-1.1B-Chat-v1.0\", task=\"text-generation\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = ChatHuggingFace(llm=llm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AIMessage(content=\"The capital of France is Paris, formally the City of Paris. The city's capital délégation is responsible for the area beyond the flat area around the city's thermal plant and some parts of Eiffel Tower. Paris is the largest metropolitan area in France, with over 16 million residents within its administrative borders.\", additional_kwargs={}, response_metadata={'token_usage': ChatCompletionOutputUsage(completion_tokens=69, prompt_tokens=29, total_tokens=98), 'model': '', 'finish_reason': 'stop'}, id='run-08dfb0a4-b7c3-4255-b85e-756b7ec7d043-0')"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.invoke(\"what is the capital of France?\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "gemini_model = ChatGoogleGenerativeAI(model=\"gemini-1.5-pro\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AIMessage(content='Paris', additional_kwargs={}, response_metadata={'prompt_feedback': {'block_reason': 0, 'safety_ratings': []}, 'finish_reason': 'STOP', 'safety_ratings': []}, id='run-f066c16a-1326-4a54-8dc3-0cdb07fcf02a-0', usage_metadata={'input_tokens': 7, 'output_tokens': 2, 'total_tokens': 9, 'input_token_details': {'cache_read': 0}})"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gemini_model.invoke(\"what is the capital of France?\")   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "groq_model = ChatGroq(model=\"deepseek-r1-distill-llama-70b\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AIMessage(content='<think>\\n\\n</think>\\n\\nThe capital of France is Paris.', additional_kwargs={}, response_metadata={'token_usage': {'completion_tokens': 12, 'prompt_tokens': 10, 'total_tokens': 22, 'completion_time': 0.043636364, 'prompt_time': 0.003496484, 'queue_time': 0.413093879, 'total_time': 0.047132848}, 'model_name': 'deepseek-r1-distill-llama-70b', 'system_fingerprint': 'fp_454c494f52', 'finish_reason': 'stop', 'logprobs': None}, id='run-7c4e834c-868d-4b22-87db-24c0c21fa45e-0', usage_metadata={'input_tokens': 10, 'output_tokens': 12, 'total_tokens': 22})"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "groq_model.invoke(\"what is the capital of France?\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "openai_model = AzureChatOpenAI(\n",
    "    api_key=os.getenv('AZURE_OPENAI_API_KEY'),\n",
    "    api_version=os.getenv('AZURE_OPENAI_API_VERSION'),\n",
    "    azure_deployment=os.getenv('AZURE_OPENAI_DEPLOYMENT'),\n",
    "    azure_endpoint=os.getenv('AZURE_OPENAI_ENDPOINT'),\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AIMessage(content='The capital of France is Paris.', additional_kwargs={'refusal': None}, response_metadata={'token_usage': {'completion_tokens': 8, 'prompt_tokens': 14, 'total_tokens': 22, 'completion_tokens_details': {'accepted_prediction_tokens': 0, 'audio_tokens': 0, 'reasoning_tokens': 0, 'rejected_prediction_tokens': 0}, 'prompt_tokens_details': {'audio_tokens': 0, 'cached_tokens': 0}}, 'model_name': 'gpt-4o-2024-05-13', 'system_fingerprint': 'fp_65792305e4', 'prompt_filter_results': [{'prompt_index': 0, 'content_filter_results': {'hate': {'filtered': False, 'severity': 'safe'}, 'jailbreak': {'filtered': False, 'detected': False}, 'self_harm': {'filtered': False, 'severity': 'safe'}, 'sexual': {'filtered': False, 'severity': 'safe'}, 'violence': {'filtered': False, 'severity': 'safe'}}}], 'finish_reason': 'stop', 'logprobs': None, 'content_filter_results': {'hate': {'filtered': False, 'severity': 'safe'}, 'protected_material_code': {'filtered': False, 'detected': False}, 'protected_material_text': {'filtered': False, 'detected': False}, 'self_harm': {'filtered': False, 'severity': 'safe'}, 'sexual': {'filtered': False, 'severity': 'safe'}, 'violence': {'filtered': False, 'severity': 'safe'}}}, id='run-6a4cf0b6-4104-421c-8887-b953f705ff9d-0', usage_metadata={'input_tokens': 14, 'output_tokens': 8, 'total_tokens': 22, 'input_token_details': {'audio': 0, 'cache_read': 0}, 'output_token_details': {'audio': 0, 'reasoning': 0}})"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "openai_model.invoke(\"what is the capital of France?\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Embedding Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_openai.embeddings import AzureOpenAIEmbeddings\n",
    "from langchain_huggingface.embeddings import HuggingFaceEmbeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "openai_embedding = AzureOpenAIEmbeddings(\n",
    "    api_key=os.getenv('AZURE_OPENAI_API_KEY'),\n",
    "    azure_deployment=os.getenv('AZURE_EMBEDDING_DEPLOYMENT_MODEL'),\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "result = openai_embedding.embed_query(\"what is the capital of France?\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1536"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "openai_embedding_64 = AzureOpenAIEmbeddings(\n",
    "    api_key=os.getenv('AZURE_OPENAI_API_KEY'),\n",
    "    azure_deployment=os.getenv('AZURE_EMBEDDING_DEPLOYMENT_MODEL'),\n",
    "    dimensions=64\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "result2 = openai_embedding_64.embed_query(\"what is the capital of France?\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "64"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(result2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "huggingface_embedding = HuggingFaceEmbeddings(model_name=\"sentence-transformers/all-MiniLM-L6-v2\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "huggingface_result = huggingface_embedding.embed_query(\"what is the capital of France?\")    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "384"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(huggingface_result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "documents = [\"what is the capital of india\",\n",
    "             \"who is the president of usa?\",\n",
    "             \"who is the prime minister of india?\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "result3 = openai_embedding.embed_documents(documents)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(result3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1536"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(result3[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "documents = [\"what is the capital of india\",\n",
    "             \"who is the president of usa?\",\n",
    "             \"who is the prime minister of india?\"]\n",
    "\n",
    "my_query = \"narendra modi is indian prime minister\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "query_embedding = openai_embedding.embed_query(my_query)\n",
    "document_embedding = openai_embedding.embed_documents(documents)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics.pairwise import cosine_similarity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "scores = cosine_similarity([query_embedding], document_embedding)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.36421902, 0.2667973 , 0.70323539]])"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_google_genai.embeddings import GoogleGenerativeAIEmbeddings\n",
    "\n",
    "google_embedding = GoogleGenerativeAIEmbeddings(model=\"models/embedding-001\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "google_result = google_embedding.embed_query(\"what is the capital of France?\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "768"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(google_result)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# PROMPTS or PROMPT_TEMPLATE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_core.messages import  HumanMessage, SystemMessage, AIMessage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # System message: Overall behaviour of the model\n",
    "\n",
    "# SystemMessage : \"You are a healthcare chatbot.\"\n",
    "# Human_Message or User_message: \"Can you suggest me a best medicine for fever?\"\n",
    "# AI_Message or Model_generated_message: \"Paracetamol/Dolo650 is the best medicine for fever\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "HumanMessage(content='How many legs does a dog have?', additional_kwargs={}, response_metadata={})"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "SystemMessage(content=\"you are a funny bot whatever you answer, you answer in a funny way\")\n",
    "\n",
    "HumanMessage(content=\"How many legs does a dog have?\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "messages = [\n",
    "    SystemMessage(content=\"you are a funny bot whatever you answer, you answer in a funny way\"),\n",
    "    HumanMessage(content=\"How many legs does a dog have?\")\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"Well, if we’re talking about a standard-issue, factory model dog, it typically comes with the full set of four legs! Two in the front for fancy paw-shakes and two in the back for enthusiastic tail-wagging stability. Unless, of course, it's a dog on the cutting edge of a new fashion trend, like roller skates or pogo sticks! But yeah, generally speaking, four-legged is the way to go.\""
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "openai_model.invoke(messages).content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "messages2 = [\n",
    "    SystemMessage(content=\"you are a angry young man, you answer everything in rude way\"),\n",
    "    HumanMessage(content=\"How many legs does a dog have?\")\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Are you serious? Even a kindergartner knows a dog has four legs. Try asking something a little less obvious next time.'"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "openai_model.invoke(messages2).content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "message3 = [\n",
    "    SystemMessage(content=\"You are a very helpful assistant. you answer everythong in detail\"),\n",
    "    HumanMessage(content=\"Tell me the role of langchain in AI development\")\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "message3.append(AIMessage(openai_model.invoke(message3).content))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[SystemMessage(content='You are a very helpful assistant. you answer everythong in detail', additional_kwargs={}, response_metadata={}),\n",
       " HumanMessage(content='Tell me the role of langchain in AI development', additional_kwargs={}, response_metadata={}),\n",
       " AIMessage(content='LangChain is an open-source framework designed to facilitate the development of AI applications that utilize large language models. Its primary focus is on enhancing the interaction with language models by integrating various functionalities and tools that streamline the development process and improve the efficiency and capabilities of AI systems. Here are some key roles and features of LangChain in AI development:\\n\\n1. **Modularity and Flexibility**: LangChain provides a modular architecture that allows developers to build complex language model-driven applications by combining different components. This modularity makes it easier to customize and extend applications according to specific needs.\\n\\n2. **Integration with External Data Sources**: LangChain can integrate with various external data sources such as databases, APIs, and knowledge graphs. This enables AI applications to incorporate real-time data and contextual information, enhancing the relevance and accuracy of responses generated by language models.\\n\\n3. **Prompt Management**: Managing prompts effectively is crucial for getting accurate and contextually appropriate outputs from language models. LangChain offers tools for prompt management, including prompt engineering, templating, and dynamic prompt generation, which help in refining the quality of interactions with language models.\\n\\n4. **Chaining of Operations**: LangChain supports the chaining of operations, where multiple language models or other computational components are linked together to perform complex tasks. This chaining capability allows for the creation of sophisticated workflows that can handle multi-step reasoning, information retrieval, and decision-making processes.\\n\\n5. **Support for Various Language Models**: LangChain is designed to work with a variety of language models, including both open-source models and commercial APIs. This flexibility allows developers to choose the most suitable model for their specific use case, balancing factors such as performance, cost, and availability.\\n\\n6. **Error Handling and Recovery**: LangChain provides mechanisms for error handling and recovery, ensuring that AI applications can manage unexpected issues gracefully and maintain robust operation. This is particularly important for maintaining user trust and providing reliable service.\\n\\n7. **User Interaction and Interfaces**: LangChain facilitates the development of user interfaces and interaction paradigms that are optimized for language model-driven applications. This includes chatbots, voice agents, and other conversational interfaces that can provide a seamless user experience.\\n\\n8. **Scalability and Deployment**: LangChain includes tools for deploying and scaling AI applications, making it easier to transition from development to production. This ensures that applications can handle varying loads and provide consistent performance.\\n\\n9. **Community and Ecosystem**: As an open-source project, LangChain benefits from a community of developers and contributors who continuously enhance the framework and share resources. This collaborative ecosystem fosters innovation and provides a wealth of shared knowledge and best practices.\\n\\nIn summary, LangChain plays a crucial role in AI development by providing a comprehensive framework that simplifies the creation, management, and deployment of applications leveraging large language models. Its modularity, integration capabilities, and support for various language models make it a powerful tool for developers working on a wide range of AI-driven solutions.', additional_kwargs={}, response_metadata={})]"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "message3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'LangChain is an open-source framework designed to facilitate the development of AI applications that utilize large language models. Its primary focus is on enhancing the interaction with language models by integrating various functionalities and tools that streamline the development process and improve the efficiency and capabilities of AI systems. Here are some key roles and features of LangChain in AI development:\\n\\n1. **Modularity and Flexibility**: LangChain provides a modular architecture that allows developers to build complex language model-driven applications by combining different components. This modularity makes it easier to customize and extend applications according to specific needs.\\n\\n2. **Integration with External Data Sources**: LangChain can integrate with various external data sources such as databases, APIs, and knowledge graphs. This enables AI applications to incorporate real-time data and contextual information, enhancing the relevance and accuracy of responses generated by language models.\\n\\n3. **Prompt Management**: Managing prompts effectively is crucial for getting accurate and contextually appropriate outputs from language models. LangChain offers tools for prompt management, including prompt engineering, templating, and dynamic prompt generation, which help in refining the quality of interactions with language models.\\n\\n4. **Chaining of Operations**: LangChain supports the chaining of operations, where multiple language models or other computational components are linked together to perform complex tasks. This chaining capability allows for the creation of sophisticated workflows that can handle multi-step reasoning, information retrieval, and decision-making processes.\\n\\n5. **Support for Various Language Models**: LangChain is designed to work with a variety of language models, including both open-source models and commercial APIs. This flexibility allows developers to choose the most suitable model for their specific use case, balancing factors such as performance, cost, and availability.\\n\\n6. **Error Handling and Recovery**: LangChain provides mechanisms for error handling and recovery, ensuring that AI applications can manage unexpected issues gracefully and maintain robust operation. This is particularly important for maintaining user trust and providing reliable service.\\n\\n7. **User Interaction and Interfaces**: LangChain facilitates the development of user interfaces and interaction paradigms that are optimized for language model-driven applications. This includes chatbots, voice agents, and other conversational interfaces that can provide a seamless user experience.\\n\\n8. **Scalability and Deployment**: LangChain includes tools for deploying and scaling AI applications, making it easier to transition from development to production. This ensures that applications can handle varying loads and provide consistent performance.\\n\\n9. **Community and Ecosystem**: As an open-source project, LangChain benefits from a community of developers and contributors who continuously enhance the framework and share resources. This collaborative ecosystem fosters innovation and provides a wealth of shared knowledge and best practices.\\n\\nIn summary, LangChain plays a crucial role in AI development by providing a comprehensive framework that simplifies the creation, management, and deployment of applications leveraging large language models. Its modularity, integration capabilities, and support for various language models make it a powerful tool for developers working on a wide range of AI-driven solutions.'"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "message3[2].content"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Create a Chatbot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "chat_history = [\n",
    "    SystemMessage(content=\"You are a helpful assistant.\")\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "while True:\n",
    "    user_input = input(\"user_input: \")\n",
    "    chat_history.append(HumanMessage(content=user_input))\n",
    "    if user_input == \"exit\":\n",
    "        break \n",
    "    response = openai_model.invoke(chat_history)\n",
    "    chat_history.append(AIMessage(content=response.content))\n",
    "    print(\"AI Generated Answer: \", response.content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[SystemMessage(content='You are a helpful assistant.', additional_kwargs={}, response_metadata={}),\n",
       " HumanMessage(content='exit', additional_kwargs={}, response_metadata={})]"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chat_history"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_core.prompts import PromptTemplate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "template = PromptTemplate(\n",
    "    template=\"Can you say hello to {name} in 5 different languages\",\n",
    "    input_variables=[\"name\"]\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "PromptTemplate(input_variables=['name'], input_types={}, partial_variables={}, template='Can you say hello to {name} in 5 different languages')"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "template"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[PromptTemplate(input_variables=['name'], input_types={}, partial_variables={}, template='Can you say hello to {name} in 5 different languages')]"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "template.get_prompts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt = template.invoke({\"name\": \"Sam\"})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Sure! Here are greetings for Sam in five different languages:\\n\\n1. English: Hello, Sam!\\n2. Spanish: ¡Hola, Sam!\\n3. French: Bonjour, Sam!\\n4. German: Hallo, Sam!\\n5. Italian: Ciao, Sam!'"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "openai_model.invoke(prompt).content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_core.prompts import ChatPromptTemplate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "chat_template = ChatPromptTemplate(\n",
    "    [\n",
    "        (\"system\", \"You are a helpful {domain} expert\"),\n",
    "        (\"user\", \"Can you provide some details about {topic}\")\n",
    "    ]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt = chat_template.invoke({\"domain\": \"Medical\", \"topic\": \"maleria\"})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ChatPromptValue(messages=[SystemMessage(content='You are a helpful Medical expert', additional_kwargs={}, response_metadata={}), HumanMessage(content='Can you provide some details about maleria', additional_kwargs={}, response_metadata={})])"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prompt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Certainly! Malaria is a life-threatening disease caused by parasites that are transmitted to people through the bites of infected female Anopheles mosquitoes. It is prevalent in tropical and subtropical regions, including many parts of Africa, Asia, and Latin America. Here are some key details about malaria:\\n\\n### Causes:\\n1. **Parasites:** The disease is caused by Plasmodium parasites. There are five species of Plasmodium that can infect humans: Plasmodium falciparum, P. vivax, P. ovale, P. malariae, and P. knowlesi. P. falciparum is the most dangerous and can lead to severe malaria and death if not treated promptly.\\n2. **Transmission:** Malaria is transmitted through the bites of infected female Anopheles mosquitoes. The parasite undergoes a life cycle phase in the mosquito before being transmitted to humans.\\n\\n### Symptoms:\\nMalaria symptoms can vary based on the species of Plasmodium and the immune status of the person. Common symptoms include:\\n- Fever\\n- Chills\\n- Sweats\\n- Headaches\\n- Nausea and vomiting\\n- Body aches\\n- Fatigue\\n\\nIn severe cases, especially with P. falciparum, symptoms can progress to:\\n- Severe anemia\\n- Respiratory distress\\n- Cerebral malaria (affecting the brain)\\n- Multi-organ failure\\n\\n### Diagnosis:\\n1. **Microscopic Examination:** Blood smears are examined under a microscope to identify the parasite.\\n2. **Rapid Diagnostic Tests (RDTs):** These tests can detect specific antigens produced by malaria parasites and provide results in about 15-20 minutes.\\n3. **Polymerase Chain Reaction (PCR):** Molecular tests that detect parasite DNA can be used but are generally more expensive and less accessible in endemic areas.\\n\\n### Treatment:\\n1. **Antimalarial Medications:** The choice of medication depends on the species of Plasmodium, the severity of infection, and the region where the infection was acquired (due to resistance patterns). Common medications include:\\n   - Artemisinin-based combination therapies (ACTs) for P. falciparum.\\n   - Chloroquine for sensitive P. vivax.\\n   - Primaquine for the radical cure of P. vivax and P. ovale to prevent relapses.\\n2. **Supportive Care:** Severe cases may require hospitalization and supportive treatments such as intravenous fluids, blood transfusions, or renal dialysis.\\n\\n### Prevention:\\n1. **Vector Control:** Measures to reduce mosquito populations and prevent bites are critical. These include:\\n   - Insecticide-treated bed nets (ITNs)\\n   - Indoor residual spraying (IRS)\\n   - Elimination of breeding sites (stagnant water)\\n2. **Prophylaxis:** Travelers to endemic areas may take antimalarial prophylactic medications before, during, and after their trip.\\n3. **Vaccination:** The RTS,S/AS01 vaccine has been approved for use in children in certain African countries, particularly for P. falciparum.\\n\\n### Public Health Measures:\\n1. **Surveillance:** Monitoring of malaria cases and resistance patterns to guide treatment policies.\\n2. **Education:** Community education on the use of bed nets, prompt treatment, and mosquito avoidance.\\n3. **Research:** Ongoing research aims to develop more effective vaccines, treatments, and vector control methods.\\n\\nMalaria remains a major global health challenge, but with continued efforts in prevention, treatment, and research, progress is being made toward reducing its impact.'"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "openai_model.invoke(prompt).content"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Chainig using LCEL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "chain = chat_template | openai_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"Certainly! Malaria is a mosquito-borne infectious disease caused by parasitic protozoans belonging to the Plasmodium genus. Here's an overview:\\n\\n### Causative Agents\\nThere are five parasite species that cause malaria in humans:\\n1. **Plasmodium falciparum** - Most deadly and prevalent, particularly in sub-Saharan Africa.\\n2. **Plasmodium vivax** - Predominantly found in Asia and Latin America; can cause chronic infection due to dormant liver stages.\\n3. **Plasmodium malariae** - More widespread, but generally causes milder symptoms.\\n4. **Plasmodium ovale** - Less common; found mainly in West Africa, can also form dormant liver stages.\\n5. **Plasmodium knowlesi** - Found in Southeast Asia, particularly in Malaysia; known for infecting macaque monkeys, but can infect humans.\\n\\n### Transmission\\nMalaria is primarily transmitted through the bites of infected female Anopheles mosquitoes, which are most active from dusk till dawn. Transmission can also occur through blood transfusions, organ transplants, use of shared needles, and from mother to unborn child during pregnancy (congenital malaria).\\n\\n### Life Cycle\\n1. **Sporozoites** injected into the human bloodstream by an infected mosquito.\\n2. Travel to the liver, where they infect hepatocytes and multiply, forming schizonts.\\n3. Schizonts rupture, releasing merozoites into the bloodstream.\\n4. Merozoites infect red blood cells (erythrocytic cycle), leading to further multiplication and periodic lysis of RBCs.\\n5. Some parasites differentiate into sexual forms called gametocytes, which are taken up by mosquitoes during blood feeding.\\n6. In the mosquito’s stomach, gametocytes mature and undergo sexual reproduction, forming ookinetes which develop into new sporozoites to continue the cycle.\\n\\n### Symptoms\\nSymptoms typically appear 10 days to 4 weeks after infection but can present as early as 7 days or even after several months due to dormant liver stages. Common symptoms include:\\n- Fever and sweating\\n- Chills (often cyclical)\\n- Headache\\n- Nausea and vomiting\\n- Muscle pain and fatigue\\n- Anemia and jaundice (yellowing of the skin and eyes)\\n\\n### Severe Complications\\nIf left untreated, malaria caused by P. falciparum can lead to severe complications such as:\\n- Cerebral malaria (seizures, coma, or neurologic damage)\\n- Severe anemia\\n- Respiratory distress\\n- Organ failure (kidneys, liver, spleen)\\n- Metabolic acidosis (particularly in children)\\n- Hypoglycemia (especially in pregnant women)\\n\\n### Diagnosis\\n- **Microscopic Examination:** Blood smears stained with Giemsa stain.\\n- **Rapid Diagnostic Tests (RDTs):** Detect antigens derived from malaria parasites.\\n- **Molecular Methods:** PCR for parasite nucleic acids, useful for detecting low parasitemia and mixed infections.\\n\\n### Treatment\\nTreatment depends on the species and severity of the infection, as well as the potential resistance patterns in the area where the malaria was contracted. Anti-malarial drugs include:\\n- **Chloroquine**\\n- **Artemisinin-based Combination Therapies (ACTs)** for P. falciparum\\n- **Primaquine** for liver stages of P. vivax and P. ovale\\n- **Atovaquone-proguanil**\\n- **Mefloquine**\\n- **Quinine** and **Doxycycline** or **Clindamycin** for severe cases\\n\\n### Prevention\\nPreventive measures include:\\n- **Insecticide-treated bed nets (ITNs)**\\n- **Indoor residual spraying (IRS)**\\n- **Prophylactic antimalarial drugs** for travelers to endemic areas\\n- **Mosquito control programs**\\n- **Vaccination:** The RTS,S/AS01 (Mosquirix) vaccine has shown efficacy against P. falciparum in children.\\n\\n### Public Health\\nControlling malaria requires coordinated efforts including education, access to medical care and preventive measures, prompt treatment, and monitoring and managing resistance patterns. The World Health Organization (WHO) and other global health organizations implement and support various malaria control and elimination programs.\\n\\nIf you need more specific information or have other questions regarding malaria, feel free to ask!\""
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chain.invoke({\"domain\": \"Medical\", \"topic\": \"maleria\"}).content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt = PromptTemplate(\n",
    "    template=\"Can you explaint the {topic} in detail\",\n",
    "    input_variables=[\"topic\"]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_core.output_parsers import  StrOutputParser"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "chain = prompt | openai_model | StrOutputParser()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'The term \"media\" refers to the various means of communication that reach or influence people widely. The media landscape is broad and multi-faceted, encompassing numerous channels and platforms. Below are the main types of media and a more detailed explanation of each:\\n\\n### 1. **Print Media:**\\n   - **Newspapers:** Periodical publications that are typically issued daily or weekly. They cover news, features, editorials, and advertisements.\\n   - **Magazines:** Periodical publications that can be weekly, monthly, or quarterly. They usually focus on specific topics such as fashion, technology, or health.\\n   - **Books:** Long-form printed works that cover virtually every topic, including fiction, non-fiction, academic texts, and more.\\n   - **Pamphlets and Brochures:** Short printed documents used for marketing, informational, or promotional purposes.\\n\\n### 2. **Broadcast Media:**\\n   - **Radio:** Audio broadcasting service transmitted through airwaves. AM, FM, and digital are common formats, featuring news, music, talk shows, and advertisements.\\n   - **Television:** Combines audio and visual components to deliver content. Includes a variety of genres from news and documentaries to entertainment, sports, and advertising.\\n\\n### 3. **Digital Media:**\\n   - **Websites and Blogs:** Online platforms for information, entertainment, and business purposes. Blogs are typically personal or focused on specific topics.\\n   - **Social Media:** Platforms where users create, share, and interact with content. Popular examples include Facebook, Twitter, Instagram, LinkedIn, and TikTok.\\n   - **Streaming Services:** Deliver multimedia content via the internet. Examples include Netflix, Hulu, Spotify, and YouTube for video and audio content.\\n   - **Podcasts:** Digital audio files available for streaming or download, often presented as a series covering diverse topics.\\n\\n### 4. **Outdoor and Transit Media:**\\n   - **Billboards:** Large outdoor boards used for advertising along highways, in cities, and on buildings.\\n   - **Transit Advertising:** Ads placed on or in transportation systems, including buses, subways, trains, and taxis.\\n   - **Posters and Banners:** Often used in public places like malls, streets, or event venues.\\n\\n### 5. **Film and Cinema:**\\n   - **Movies and Documentaries:** Produced for entertainment, education, or propaganda. Viewed in cinemas or through digital streaming services.\\n\\n### Advertising and the Media:\\nAdvertising is a significant component of many media types, providing the financial investment necessary to produce and distribute content while promoting products and services to consumers.\\n\\n### Media Functions:\\n- **Information:** Provides news and information to the public.\\n- **Entertainment:** Offers a wide range of entertainment from music and films to online games and social media.\\n- **Education:** Disseminates educational content and critical information.\\n- **Surveillance:** Keeps an eye on those in power and reports their actions to ensure accountability.\\n- **Socialization:** Helps people learn societal norms and values.\\n- **Cultural Transmission:** Reflects and informs cultural norms, traditions, and identities.\\n\\n### Media Impact:\\n- **Cultural Influence:** Media shapes and reflects cultural norms and societal values.\\n- **Political Influence:** Plays a crucial role in shaping political opinions and agendas.\\n- **Economic Impact:** Influences consumer behavior and business practices.\\n- **Social Impact:** Affects social behaviors, relationships, and community engagement.\\n\\n### Challenges:\\n- **Access and Equity:** Bridging the digital divide to ensure all demographic groups can access media.\\n- **Bias and Representation:** Addressing biases and ensuring diverse and accurate representation.\\n- **Regulation and Censorship:** Balancing freedom of speech with responsible content regulation.\\n\\nIn summary, the media is a vast and complex domain that plays a vital role in modern society by disseminating information, providing entertainment, and shaping public discourse. As technology evolves, the media landscape continues to transform, offering new forms of engagement and posing new challenges and opportunities.\\n'"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chain.invoke({\"topic\": \"media\"})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     +-------------+       \n",
      "     | PromptInput |       \n",
      "     +-------------+       \n",
      "            *              \n",
      "            *              \n",
      "            *              \n",
      "    +----------------+     \n",
      "    | PromptTemplate |     \n",
      "    +----------------+     \n",
      "            *              \n",
      "            *              \n",
      "            *              \n",
      "   +-----------------+     \n",
      "   | AzureChatOpenAI |     \n",
      "   +-----------------+     \n",
      "            *              \n",
      "            *              \n",
      "            *              \n",
      "   +-----------------+     \n",
      "   | StrOutputParser |     \n",
      "   +-----------------+     \n",
      "            *              \n",
      "            *              \n",
      "            *              \n",
      "+-----------------------+  \n",
      "| StrOutputParserOutput |  \n",
      "+-----------------------+  \n"
     ]
    }
   ],
   "source": [
    "chain.get_graph().print_ascii()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Sequential llm Chain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt1 = PromptTemplate(\n",
    "    template=\"Give me a detail report on {topic}\",\n",
    "    input_variables=[\"topic\"]\n",
    ")\n",
    "\n",
    "prompt2 = PromptTemplate(\n",
    "    template=\"Generate 3 important points on {summary}\",\n",
    "    input_variables=[\"summary\"]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "parser = StrOutputParser()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    "chain = prompt1 | openai_model | parser | prompt2 | openai_model | parser"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    "result = chain.invoke({\"topic\": \"Machine learning\"})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Certainly! Below are three critical points derived from the detailed report on machine learning:\n",
      "\n",
      "1. **Types of Machine Learning:**\n",
      "   - Machine learning is categorized into three primary types based on the learning task: supervised, unsupervised, and reinforcement learning.\n",
      "     - **Supervised Learning:** Algorithms learn from labeled data to predict outcomes for new data (e.g., Linear Regression, Decision Trees).\n",
      "     - **Unsupervised Learning:** Algorithms identify patterns and relationships from unlabeled data (e.g., K-means Clustering, PCA).\n",
      "     - **Reinforcement Learning:** Agents learn to make decisions by interacting with an environment to maximize rewards (e.g., Q-Learning, DQN).\n",
      "\n",
      "2. **Key Concepts and Techniques:**\n",
      "   - **Data Preprocessing:** Essential steps include handling missing values, feature scaling, and encoding categorical variables.\n",
      "   - **Feature Engineering:** Creating or modifying features to enhance model performance, including polynomial features and interaction terms.\n",
      "   - **Model Evaluation and Selection:** Using metrics like MAE, MSE for regression tasks, and accuracy, precision, recall for classification to assess performance. Cross-validation techniques ensure model generalizability.\n",
      "   - **Model Optimization:** Techniques such as Grid Search and Random Search are used for optimal hyperparameter tuning.\n",
      "\n",
      "3. **Applications of Machine Learning:**\n",
      "   - **Healthcare:** Applications include disease prediction/diagnosis, personalized treatments, and drug discovery.\n",
      "   - **Finance:** Used for fraud detection, algorithmic trading, and risk management.\n",
      "   - **Retail:** Implemented in product recommendations, inventory management, and customer sentiment analysis.\n",
      "   - **Manufacturing:** Applications such as predictive maintenance, quality control, and supply chain optimization.\n",
      "   - **Transportation:** Includes advancements in autonomous vehicles, route optimization, and demand prediction for ride-sharing services.\n",
      "\n",
      "These points emphasize the foundational aspects, indispensable techniques, and diverse applications of machine learning across various fields.\n"
     ]
    }
   ],
   "source": [
    "print(result)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Parallel chaining"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt1 = PromptTemplate(\n",
    "    template=\"Generate simple summary from the following text \\n {text}\",\n",
    "    input_variables=[\"text\"]\n",
    ")\n",
    "\n",
    "prompt2 = PromptTemplate(\n",
    "    template=\"generate 3 question and answer from the given text \\n {text}\",\n",
    "    input_variables=[\"text\"]\n",
    ")\n",
    "\n",
    "prompt3 = PromptTemplate(\n",
    "    template=\"Merge the provided summary and Questions and answers into a single document \\n Summary: {summary} q&A: {qa}\",\n",
    "    input_variables=[\"summary\", \"qa\"]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.schema.runnable import RunnableParallel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [],
   "source": [
    "parallel_chain = RunnableParallel(\n",
    "    {\n",
    "    \"summary\": prompt1 | openai_model | parser,\n",
    "    \"qa\": prompt2 | openai_model | parser\n",
    "    }\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [],
   "source": [
    "merge_chain = prompt3 | openai_model | parser"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [],
   "source": [
    "chain = parallel_chain | merge_chain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              +---------------------------+              \n",
      "              | Parallel<summary,qa>Input |              \n",
      "              +---------------------------+              \n",
      "                  ***               ***                  \n",
      "               ***                     ***               \n",
      "             **                           **             \n",
      "+----------------+                    +----------------+ \n",
      "| PromptTemplate |                    | PromptTemplate | \n",
      "+----------------+                    +----------------+ \n",
      "          *                                   *          \n",
      "          *                                   *          \n",
      "          *                                   *          \n",
      "+-----------------+                  +-----------------+ \n",
      "| AzureChatOpenAI |                  | AzureChatOpenAI | \n",
      "+-----------------+                  +-----------------+ \n",
      "          *                                   *          \n",
      "          *                                   *          \n",
      "          *                                   *          \n",
      "+-----------------+                  +-----------------+ \n",
      "| StrOutputParser |                  | StrOutputParser | \n",
      "+-----------------+                  +-----------------+ \n",
      "                  ***               ***                  \n",
      "                     ***         ***                     \n",
      "                        **     **                        \n",
      "             +----------------------------+              \n",
      "             | Parallel<summary,qa>Output |              \n",
      "             +----------------------------+              \n",
      "                            *                            \n",
      "                            *                            \n",
      "                            *                            \n",
      "                   +----------------+                    \n",
      "                   | PromptTemplate |                    \n",
      "                   +----------------+                    \n",
      "                            *                            \n",
      "                            *                            \n",
      "                            *                            \n",
      "                  +-----------------+                    \n",
      "                  | AzureChatOpenAI |                    \n",
      "                  +-----------------+                    \n",
      "                            *                            \n",
      "                            *                            \n",
      "                            *                            \n",
      "                  +-----------------+                    \n",
      "                  | StrOutputParser |                    \n",
      "                  +-----------------+                    \n",
      "                            *                            \n",
      "                            *                            \n",
      "                            *                            \n",
      "                +-----------------------+                \n",
      "                | StrOutputParserOutput |                \n",
      "                +-----------------------+                \n"
     ]
    }
   ],
   "source": [
    "chain.get_graph().print_ascii()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [],
   "source": [
    "text = \"\"\"In artificial intelligence, an intelligent agent is an entity that perceives its environment, takes actions autonomously to achieve goals, and may improve its performance through machine learning or by acquiring knowledge. Leading AI textbooks define artificial intelligence as the \"study and design of intelligent agents,\" emphasizing that goal-directed behavior is central to intelligence.\n",
    "\n",
    "A specialized subset of intelligent agents, agentic AI (also known as an AI agent or simply agent), expands this concept by proactively pursuing goals, making decisions, and taking actions over extended periods, thereby exemplifying a novel form of digital agency.[1]\n",
    "\n",
    "Intelligent agents can range from simple to highly complex. A basic thermostat or control system is considered an intelligent agent, as is a human being, or any other system that meets the same criteria—such as a firm, a state, or a biome.[2]\n",
    "\n",
    "Intelligent agents operate based on an objective function, which encapsulates their goals. They are designed to create and execute plans that maximize the expected value of this function upon completion.[3] For example, a reinforcement learning agent has a reward function, which allows programmers to shape its desired behavior.[4] Similarly, an evolutionary algorithm's behavior is guided by a fitness function.[5]\n",
    "\n",
    "Intelligent agents in artificial intelligence are closely related to agents in economics, and versions of the intelligent agent paradigm are studied in cognitive science, ethics, and the philosophy of practical reason, as well as in many interdisciplinary socio-cognitive modeling and computer social simulations.\n",
    "\n",
    "Intelligent agents are often described schematically as abstract functional systems similar to computer programs. To distinguish theoretical models from real-world implementations, abstract descriptions of intelligent agents are called abstract intelligent agents. Intelligent agents are also closely related to software agents—autonomous computer programs that carry out tasks on behalf of users. They are also referred to using a term borrowed from economics: a \"rational agent\".[2]\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [],
   "source": [
    "result = chain.invoke({\"text\": text})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "**Document: Intelligent Agents in AI**\n",
      "\n",
      "### Summary:\n",
      "In artificial intelligence, an intelligent agent is an entity that perceives its environment, autonomously takes actions to achieve goals, and may enhance its performance through machine learning or acquiring knowledge. AI textbooks define AI as the study and design of intelligent agents with goal-directed behavior as central to intelligence. Intelligent agents can be simple, like a thermostat, or complex, like a human or a firm. They operate based on an objective function that guides their actions to maximize expected value. Agentic AI, a specialized subset, actively pursues goals over extended periods. Intelligent agents are closely related to economic agents and are studied across various disciplines. They are often conceptualized as abstract functional systems and are also related to software agents or rational agents in economics. \n",
      "\n",
      "### Questions and Answers:\n",
      "#### Question 1:\n",
      "What is an intelligent agent in the context of artificial intelligence?\n",
      "\n",
      "**Answer:**\n",
      "In artificial intelligence, an intelligent agent is an entity that perceives its environment, takes actions autonomously to achieve goals, and may improve its performance through machine learning or by acquiring knowledge.\n",
      "\n",
      "#### Question 2:\n",
      "What is an \"agentic AI\" and how does it differ from a basic intelligent agent?\n",
      "\n",
      "**Answer:**\n",
      "Agentic AI, also known as an AI agent or simply an agent, is a specialized subset of intelligent agents that proactively pursues goals, makes decisions, and takes actions over extended periods. This exemplifies a novel form of digital agency, distinguishing it from basic intelligent agents.\n",
      "\n",
      "#### Question 3:\n",
      "How do intelligent agents make decisions and pursue goals?\n",
      "\n",
      "**Answer:**\n",
      "Intelligent agents operate based on an objective function that encapsulates their goals. They are designed to create and execute plans to maximize the expected value of this function upon completion. For example, a reinforcement learning agent has a reward function to shape its behavior, while an evolutionary algorithm is guided by a fitness function.\n"
     ]
    }
   ],
   "source": [
    "print(result)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# JSON output parser"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_core.output_parsers import  JsonOutputParser"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [],
   "source": [
    "parser = JsonOutputParser()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Return a JSON object.'"
      ]
     },
     "execution_count": 90,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "parser.get_format_instructions()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [],
   "source": [
    "template = PromptTemplate(\n",
    "    template=\"give me name, age and city from the given text {text} \\n {format_instructions}\",\n",
    "    input_variables=[\"text\"],\n",
    "    partial_variables={\"format_instructions\": parser.get_format_instructions()}\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [],
   "source": [
    "text = \"my name is bob, i am 25 year old and i live in newyork\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'give me name, age and city from the given text my name is bob, i am 25 year old and i live in newyork \\n Return a JSON object.'"
      ]
     },
     "execution_count": 93,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "template.format(text=text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt = template.format(text=text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [],
   "source": [
    "result = openai_model.invoke(prompt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AIMessage(content='Sure, here is the JSON object based on the provided information:\\n\\n```json\\n{\\n  \"name\": \"bob\",\\n  \"age\": 25,\\n  \"city\": \"newyork\"\\n}\\n```', additional_kwargs={'refusal': None}, response_metadata={'token_usage': {'completion_tokens': 43, 'prompt_tokens': 42, 'total_tokens': 85, 'completion_tokens_details': {'accepted_prediction_tokens': 0, 'audio_tokens': 0, 'reasoning_tokens': 0, 'rejected_prediction_tokens': 0}, 'prompt_tokens_details': {'audio_tokens': 0, 'cached_tokens': 0}}, 'model_name': 'gpt-4o-2024-05-13', 'system_fingerprint': 'fp_65792305e4', 'prompt_filter_results': [{'prompt_index': 0, 'content_filter_results': {'hate': {'filtered': False, 'severity': 'safe'}, 'jailbreak': {'filtered': False, 'detected': False}, 'self_harm': {'filtered': False, 'severity': 'safe'}, 'sexual': {'filtered': False, 'severity': 'safe'}, 'violence': {'filtered': False, 'severity': 'safe'}}}], 'finish_reason': 'stop', 'logprobs': None, 'content_filter_results': {'hate': {'filtered': False, 'severity': 'safe'}, 'self_harm': {'filtered': False, 'severity': 'safe'}, 'sexual': {'filtered': False, 'severity': 'safe'}, 'violence': {'filtered': False, 'severity': 'safe'}}}, id='run-58ad8a98-3821-46b8-b654-1d7bf51f82e3-0', usage_metadata={'input_tokens': 42, 'output_tokens': 43, 'total_tokens': 85, 'input_token_details': {'audio': 0, 'cache_read': 0}, 'output_token_details': {'audio': 0, 'reasoning': 0}})"
      ]
     },
     "execution_count": 96,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Sure, here is the JSON object based on the provided information:\\n\\n```json\\n{\\n  \"name\": \"bob\",\\n  \"age\": 25,\\n  \"city\": \"newyork\"\\n}\\n```'"
      ]
     },
     "execution_count": 97,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result.content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [],
   "source": [
    "result = parser.parse(result.content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'bob'"
      ]
     },
     "execution_count": 99,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result['name']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "25"
      ]
     },
     "execution_count": 100,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result['age']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [],
   "source": [
    "chain = template | openai_model | parser"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'name': 'bob', 'age': 25, 'city': 'newyork'}"
      ]
     },
     "execution_count": 102,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chain.invoke({\"text\": text})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [],
   "source": [
    "template2 = PromptTemplate(\n",
    "    template=\"Give me 5 facts about {topic} \\n {format_instrucitons}\",\n",
    "    input_variables=[\"topic\"],\n",
    "    partial_variables={\"format_instrucitons\": parser.get_format_instructions()}\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [],
   "source": [
    "chain = template2 | openai_model |parser"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'fact1': 'Machine learning is a subset of artificial intelligence that focuses on the development of algorithms that allow computers to learn and make predictions based on data.',\n",
       " 'fact2': 'There are three main types of machine learning: supervised learning, unsupervised learning, and reinforcement learning.',\n",
       " 'fact3': 'In supervised learning, the algorithm is trained on a labeled dataset, which means that each training example is paired with an output label.',\n",
       " 'fact4': 'Unsupervised learning involves training on a dataset without labeled responses, and the system tries to learn the patterns and structure from the data.',\n",
       " 'fact5': 'Reinforcement learning is a type of machine learning where an agent learns to make decisions by performing certain actions and receiving rewards or penalties as feedback.'}"
      ]
     },
     "execution_count": 105,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chain.invoke({\"topic\": \"Machine learning\"})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [],
   "source": [
    "topic = \"\"\"In artificial intelligence, an intelligent agent is an entity that perceives its environment, takes actions autonomously to achieve goals, and may improve its performance through machine learning or by acquiring knowledge. Leading AI textbooks define artificial intelligence as the \"study and design of intelligent agents,\" emphasizing that goal-directed behavior is central to intelligence.\n",
    "\n",
    "A specialized subset of intelligent agents, agentic AI (also known as an AI agent or simply agent), expands this concept by proactively pursuing goals, making decisions, and taking actions over extended periods, thereby exemplifying a novel form of digital agency.[1]\n",
    "\n",
    "Intelligent agents can range from simple to highly complex. A basic thermostat or control system is considered an intelligent agent, as is a human being, or any other system that meets the same criteria—such as a firm, a state, or a biome.[2]\n",
    "\n",
    "Intelligent agents operate based on an objective function, which encapsulates their goals. They are designed to create and execute plans that maximize the expected value of this function upon completion.[3] For example, a reinforcement learning agent has a reward function, which allows programmers to shape its desired behavior.[4] Similarly, an evolutionary algorithm's behavior is guided by a fitness function.[5]\n",
    "\n",
    "Intelligent agents in artificial intelligence are closely related to agents in economics, and versions of the intelligent agent paradigm are studied in cognitive science, ethics, and the philosophy of practical reason, as well as in many interdisciplinary socio-cognitive modeling and computer social simulations.\n",
    "\n",
    "Intelligent agents are often described schematically as abstract functional systems similar to computer programs. To distinguish theoretical models from real-world implementations, abstract descriptions of intelligent agents are called abstract intelligent agents. Intelligent agents are also closely related to software agents—autonomous computer programs that carry out tasks on behalf of users. They are also referred to using a term borrowed from economics: a \"rational agent\".[2]\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [],
   "source": [
    "chain = template2 | openai_model | parser   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'fact1': 'An intelligent agent perceives its environment and takes actions autonomously to achieve goals, potentially improving its performance through machine learning or by acquiring knowledge.',\n",
       " 'fact2': 'Agentic AI, a specialized subset of intelligent agents, proactively pursues goals, makes decisions, and takes actions over extended periods, showcasing a novel form of digital agency.',\n",
       " 'fact3': 'Intelligent agents can range from simple systems like thermostats to complex entities like humans, firms, states, or biomes.',\n",
       " 'fact4': 'Intelligent agents operate based on an objective function encapsulating their goals, executing plans to maximize the expected value of this function. Examples include reinforcement learning agents with reward functions and evolutionary algorithms guided by fitness functions.',\n",
       " 'fact5': 'Intelligent agents in AI are related to agents in economics, and are studied in fields like cognitive science, ethics, philosophy, socio-cognitive modeling, and computer social simulations. Abstract intelligent agents represent theoretical models, while software agents carry out tasks on behalf of users, often described as rational agents.'}"
      ]
     },
     "execution_count": 108,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chain.invoke({\"topic\": topic})   "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Generate a Strcture output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.output_parsers.structured import StructuredOutputParser, ResponseSchema"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [],
   "source": [
    "schema = [\n",
    "    ResponseSchema(name=\"first_fact\", description=\"first fact about the topic\"),\n",
    "    ResponseSchema(name=\"second_fact\", description=\"second fact about the topic\"),\n",
    "    ResponseSchema(name=\"third_fact\", description=\"third fact about the topic\"),\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [],
   "source": [
    "parser = StructuredOutputParser.from_response_schemas(schema)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [],
   "source": [
    "template3 = PromptTemplate(\n",
    "    template=\"Give me 3 facts about {topic} \\n {format_instructions}\",\n",
    "    input_variables=[\"topic\"],\n",
    "    partial_variables={\"format_instructions\": parser.get_format_instructions()}\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [],
   "source": [
    "chain = template3 | openai_model | parser"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [],
   "source": [
    "result = chain.invoke({\"topic\": topic})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'first_fact': 'In artificial intelligence, an intelligent agent perceives its environment and takes actions autonomously to achieve goals, improving its performance through machine learning or acquiring knowledge.',\n",
       " 'second_fact': 'A specialized type of intelligent agent, known as agentic AI, proactively pursues goals, makes decisions, and takes actions over extended periods.',\n",
       " 'third_fact': 'Intelligent agents operate based on an objective function that encapsulates their goals, creating and executing plans to maximize the expected value of this function.'}"
      ]
     },
     "execution_count": 115,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Pydantic Output parser"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pydantic import  BaseModel, Field"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Person(BaseModel):\n",
    "    name: str = Field(description=\"name of the person\")\n",
    "    age: int = Field(gt=18, description=\"age of the person\")\n",
    "    city: str = Field(description=\"city of the person\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_core.output_parsers import  PydanticOutputParser"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [],
   "source": [
    "parser = PydanticOutputParser(pydantic_object=Person)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'The output should be formatted as a JSON instance that conforms to the JSON schema below.\\n\\nAs an example, for the schema {\"properties\": {\"foo\": {\"title\": \"Foo\", \"description\": \"a list of strings\", \"type\": \"array\", \"items\": {\"type\": \"string\"}}}, \"required\": [\"foo\"]}\\nthe object {\"foo\": [\"bar\", \"baz\"]} is a well-formatted instance of the schema. The object {\"properties\": {\"foo\": [\"bar\", \"baz\"]}} is not well-formatted.\\n\\nHere is the output schema:\\n```\\n{\"properties\": {\"name\": {\"description\": \"name of the person\", \"title\": \"Name\", \"type\": \"string\"}, \"age\": {\"description\": \"age of the person\", \"exclusiveMinimum\": 18, \"title\": \"Age\", \"type\": \"integer\"}, \"city\": {\"description\": \"city of the person\", \"title\": \"City\", \"type\": \"string\"}}, \"required\": [\"name\", \"age\", \"city\"]}\\n```'"
      ]
     },
     "execution_count": 120,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "parser.get_format_instructions()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [],
   "source": [
    "template = PromptTemplate(\n",
    "    template=\"extract name, age and city from the given text {text} \\n {format_instructions}\",\n",
    "    input_variables=[\"text\"],\n",
    "    partial_variables={\"format_instructions\": parser.get_format_instructions()}\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [],
   "source": [
    "chain = template | openai_model | parser"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {},
   "outputs": [],
   "source": [
    "text = \"my name is bob, i am 25 year old and i live in newyork. And my friend is Anand and he is from Bangalore\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {},
   "outputs": [],
   "source": [
    "result = chain.invoke({\"text\": text})    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Person(name='bob', age=25, city='newyork')"
      ]
     },
     "execution_count": 131,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'bob'"
      ]
     },
     "execution_count": 132,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result.name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "25"
      ]
     },
     "execution_count": 133,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result.age"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'newyork'"
      ]
     },
     "execution_count": 134,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result.city"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "langchain",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
